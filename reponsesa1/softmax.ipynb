{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.320144\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -1.631721 analytic: -1.631721, relative error: 3.036222e-08\n",
      "numerical: 0.139119 analytic: 0.139119, relative error: 2.589401e-07\n",
      "numerical: -0.838928 analytic: -0.838928, relative error: 4.823237e-08\n",
      "numerical: 1.151834 analytic: 1.151834, relative error: 3.930164e-09\n",
      "numerical: 1.334531 analytic: 1.334531, relative error: 2.019360e-08\n",
      "numerical: 1.621128 analytic: 1.621128, relative error: 6.393246e-09\n",
      "numerical: -0.451897 analytic: -0.451897, relative error: 5.805443e-08\n",
      "numerical: 1.260335 analytic: 1.260335, relative error: 7.285205e-08\n",
      "numerical: 2.105805 analytic: 2.105805, relative error: 4.179480e-08\n",
      "numerical: 4.326988 analytic: 4.326988, relative error: 5.276599e-09\n",
      "numerical: 0.301015 analytic: 0.301015, relative error: 1.111807e-07\n",
      "numerical: 0.318397 analytic: 0.318397, relative error: 1.571433e-08\n",
      "numerical: 1.878616 analytic: 1.878616, relative error: 2.616105e-08\n",
      "numerical: 1.420289 analytic: 1.420289, relative error: 1.625442e-08\n",
      "numerical: -1.644341 analytic: -1.644341, relative error: 2.581560e-09\n",
      "numerical: -0.817758 analytic: -0.817758, relative error: 5.775792e-10\n",
      "numerical: -0.748185 analytic: -0.748185, relative error: 4.674193e-08\n",
      "numerical: -0.323669 analytic: -0.323669, relative error: 1.260322e-07\n",
      "numerical: -0.059232 analytic: -0.059233, relative error: 6.053040e-07\n",
      "numerical: -0.653350 analytic: -0.653350, relative error: 9.709716e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.320144e+00 computed in 0.112925s\n",
      "vectorized loss: 2.320144e+00 computed in 0.042372s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 5.835128\n",
      "iteration 100 / 1500: loss 2.519531\n",
      "iteration 200 / 1500: loss 2.467565\n",
      "iteration 300 / 1500: loss 2.260135\n",
      "iteration 400 / 1500: loss 2.146513\n",
      "iteration 500 / 1500: loss 2.088020\n",
      "iteration 600 / 1500: loss 2.008430\n",
      "iteration 700 / 1500: loss 1.901445\n",
      "iteration 800 / 1500: loss 1.973939\n",
      "iteration 900 / 1500: loss 1.974937\n",
      "iteration 1000 / 1500: loss 1.815678\n",
      "iteration 1100 / 1500: loss 1.823532\n",
      "iteration 1200 / 1500: loss 1.849061\n",
      "iteration 1300 / 1500: loss 1.799322\n",
      "iteration 1400 / 1500: loss 1.642871\n",
      "iteration 0 / 1500: loss 5.830218\n",
      "iteration 100 / 1500: loss 1.801432\n",
      "iteration 200 / 1500: loss 1.837329\n",
      "iteration 300 / 1500: loss 1.937339\n",
      "iteration 400 / 1500: loss 1.953840\n",
      "iteration 500 / 1500: loss 1.988566\n",
      "iteration 600 / 1500: loss 1.798882\n",
      "iteration 700 / 1500: loss 1.796646\n",
      "iteration 800 / 1500: loss 1.948079\n",
      "iteration 900 / 1500: loss 1.947005\n",
      "iteration 1000 / 1500: loss 1.912279\n",
      "iteration 1100 / 1500: loss 1.876153\n",
      "iteration 1200 / 1500: loss 1.851250\n",
      "iteration 1300 / 1500: loss 1.863762\n",
      "iteration 1400 / 1500: loss 1.891275\n",
      "iteration 0 / 1500: loss 6.331465\n",
      "iteration 100 / 1500: loss 2.160922\n",
      "iteration 200 / 1500: loss 2.123351\n",
      "iteration 300 / 1500: loss 2.064288\n",
      "iteration 400 / 1500: loss 2.132280\n",
      "iteration 500 / 1500: loss 2.078973\n",
      "iteration 600 / 1500: loss 2.089512\n",
      "iteration 700 / 1500: loss 2.101445\n",
      "iteration 800 / 1500: loss 2.098807\n",
      "iteration 900 / 1500: loss 2.100785\n",
      "iteration 1000 / 1500: loss 2.080627\n",
      "iteration 1100 / 1500: loss 2.079227\n",
      "iteration 1200 / 1500: loss 2.048890\n",
      "iteration 1300 / 1500: loss 2.041218\n",
      "iteration 1400 / 1500: loss 2.119275\n",
      "iteration 0 / 1500: loss 6.298991\n",
      "iteration 100 / 1500: loss 2.328145\n",
      "iteration 200 / 1500: loss 2.080963\n",
      "iteration 300 / 1500: loss 1.787901\n",
      "iteration 400 / 1500: loss 1.857193\n",
      "iteration 500 / 1500: loss 1.748454\n",
      "iteration 600 / 1500: loss 1.777398\n",
      "iteration 700 / 1500: loss 1.748689\n",
      "iteration 800 / 1500: loss 1.711451\n",
      "iteration 900 / 1500: loss 1.737809\n",
      "iteration 1000 / 1500: loss 1.815742\n",
      "iteration 1100 / 1500: loss 1.693689\n",
      "iteration 1200 / 1500: loss 1.689891\n",
      "iteration 1300 / 1500: loss 1.815884\n",
      "iteration 1400 / 1500: loss 1.707488\n",
      "iteration 0 / 1500: loss 5.580874\n",
      "iteration 100 / 1500: loss 3.089748\n",
      "iteration 200 / 1500: loss 2.336127\n",
      "iteration 300 / 1500: loss 2.192025\n",
      "iteration 400 / 1500: loss 2.034092\n",
      "iteration 500 / 1500: loss 1.953596\n",
      "iteration 600 / 1500: loss 1.931166\n",
      "iteration 700 / 1500: loss 2.033032\n",
      "iteration 800 / 1500: loss 1.872946\n",
      "iteration 900 / 1500: loss 1.983414\n",
      "iteration 1000 / 1500: loss 1.887828\n",
      "iteration 1100 / 1500: loss 1.950081\n",
      "iteration 1200 / 1500: loss 1.922331\n",
      "iteration 1300 / 1500: loss 1.944468\n",
      "iteration 1400 / 1500: loss 1.830475\n",
      "iteration 0 / 1500: loss 5.890217\n",
      "iteration 100 / 1500: loss 2.256458\n",
      "iteration 200 / 1500: loss 1.959072\n",
      "iteration 300 / 1500: loss 1.859990\n",
      "iteration 400 / 1500: loss 1.932910\n",
      "iteration 500 / 1500: loss 1.895223\n",
      "iteration 600 / 1500: loss 1.881908\n",
      "iteration 700 / 1500: loss 1.810698\n",
      "iteration 800 / 1500: loss 1.833084\n",
      "iteration 900 / 1500: loss 1.760400\n",
      "iteration 1000 / 1500: loss 1.624579\n",
      "iteration 1100 / 1500: loss 1.836171\n",
      "iteration 1200 / 1500: loss 1.662358\n",
      "iteration 1300 / 1500: loss 1.769927\n",
      "iteration 1400 / 1500: loss 1.808440\n",
      "iteration 0 / 1500: loss 6.110197\n",
      "iteration 100 / 1500: loss 3.963726\n",
      "iteration 200 / 1500: loss 3.422107\n",
      "iteration 300 / 1500: loss 3.486636\n",
      "iteration 400 / 1500: loss 3.029198\n",
      "iteration 500 / 1500: loss 3.015405\n",
      "iteration 600 / 1500: loss 3.055932\n",
      "iteration 700 / 1500: loss 2.754498\n",
      "iteration 800 / 1500: loss 2.973893\n",
      "iteration 900 / 1500: loss 2.796904\n",
      "iteration 1000 / 1500: loss 2.632165\n",
      "iteration 1100 / 1500: loss 2.419671\n",
      "iteration 1200 / 1500: loss 2.430306\n",
      "iteration 1300 / 1500: loss 2.353689\n",
      "iteration 1400 / 1500: loss 2.591412\n",
      "iteration 0 / 1500: loss 6.687017\n",
      "iteration 100 / 1500: loss 1.955754\n",
      "iteration 200 / 1500: loss 1.872894\n",
      "iteration 300 / 1500: loss 1.906989\n",
      "iteration 400 / 1500: loss 1.865603\n",
      "iteration 500 / 1500: loss 1.867819\n",
      "iteration 600 / 1500: loss 1.865176\n",
      "iteration 700 / 1500: loss 1.870228\n",
      "iteration 800 / 1500: loss 1.912802\n",
      "iteration 900 / 1500: loss 1.899352\n",
      "iteration 1000 / 1500: loss 1.884551\n",
      "iteration 1100 / 1500: loss 1.835178\n",
      "iteration 1200 / 1500: loss 1.995331\n",
      "iteration 1300 / 1500: loss 1.813286\n",
      "iteration 1400 / 1500: loss 1.861637\n",
      "iteration 0 / 1500: loss 5.184682\n",
      "iteration 100 / 1500: loss 3.712094\n",
      "iteration 200 / 1500: loss 3.239687\n",
      "iteration 300 / 1500: loss 2.655697\n",
      "iteration 400 / 1500: loss 2.420515\n",
      "iteration 500 / 1500: loss 2.393040\n",
      "iteration 600 / 1500: loss 2.432791\n",
      "iteration 700 / 1500: loss 2.314644\n",
      "iteration 800 / 1500: loss 2.150992\n",
      "iteration 900 / 1500: loss 2.073842\n",
      "iteration 1000 / 1500: loss 2.056714\n",
      "iteration 1100 / 1500: loss 1.942148\n",
      "iteration 1200 / 1500: loss 1.980363\n",
      "iteration 1300 / 1500: loss 2.010823\n",
      "iteration 1400 / 1500: loss 2.054704\n",
      "iteration 0 / 1500: loss 6.072283\n",
      "iteration 100 / 1500: loss nan\n",
      "iteration 200 / 1500: loss nan\n",
      "iteration 300 / 1500: loss nan\n",
      "iteration 400 / 1500: loss nan\n",
      "iteration 500 / 1500: loss nan\n",
      "iteration 600 / 1500: loss nan\n",
      "iteration 700 / 1500: loss nan\n",
      "iteration 800 / 1500: loss nan\n",
      "iteration 900 / 1500: loss nan\n",
      "iteration 1000 / 1500: loss nan\n",
      "iteration 1100 / 1500: loss nan\n",
      "iteration 1200 / 1500: loss nan\n",
      "iteration 1300 / 1500: loss nan\n",
      "iteration 1400 / 1500: loss nan\n",
      "iteration 0 / 1500: loss 5.514875\n",
      "iteration 100 / 1500: loss 2.051522\n",
      "iteration 200 / 1500: loss 2.019270\n",
      "iteration 300 / 1500: loss 2.049532\n",
      "iteration 400 / 1500: loss 2.094359\n",
      "iteration 500 / 1500: loss 2.030713\n",
      "iteration 600 / 1500: loss 2.012582\n",
      "iteration 700 / 1500: loss 1.987419\n",
      "iteration 800 / 1500: loss 2.034624\n",
      "iteration 900 / 1500: loss 2.074244\n",
      "iteration 1000 / 1500: loss 2.029992\n",
      "iteration 1100 / 1500: loss 2.028290\n",
      "iteration 1200 / 1500: loss 2.060990\n",
      "iteration 1300 / 1500: loss 2.055363\n",
      "iteration 1400 / 1500: loss 2.048115\n",
      "iteration 0 / 1500: loss 5.183492\n",
      "iteration 100 / 1500: loss 1.908245\n",
      "iteration 200 / 1500: loss 1.806737\n",
      "iteration 300 / 1500: loss 1.827351\n",
      "iteration 400 / 1500: loss 1.846181\n",
      "iteration 500 / 1500: loss 1.788577\n",
      "iteration 600 / 1500: loss 1.876371\n",
      "iteration 700 / 1500: loss 1.897936\n",
      "iteration 800 / 1500: loss 1.835036\n",
      "iteration 900 / 1500: loss 1.765512\n",
      "iteration 1000 / 1500: loss 1.816578\n",
      "iteration 1100 / 1500: loss 1.784150\n",
      "iteration 1200 / 1500: loss 1.837115\n",
      "iteration 1300 / 1500: loss 1.934496\n",
      "iteration 1400 / 1500: loss 1.864773\n",
      "iteration 0 / 1500: loss 6.045401\n",
      "iteration 100 / 1500: loss 3.041245\n",
      "iteration 200 / 1500: loss 2.854545\n",
      "iteration 300 / 1500: loss 2.637322\n",
      "iteration 400 / 1500: loss 2.431588\n",
      "iteration 500 / 1500: loss 2.213026\n",
      "iteration 600 / 1500: loss 2.269885\n",
      "iteration 700 / 1500: loss 2.269464\n",
      "iteration 800 / 1500: loss 2.292834\n",
      "iteration 900 / 1500: loss 2.309667\n",
      "iteration 1000 / 1500: loss 2.045476\n",
      "iteration 1100 / 1500: loss 1.983118\n",
      "iteration 1200 / 1500: loss 2.087931\n",
      "iteration 1300 / 1500: loss 1.933046\n",
      "iteration 1400 / 1500: loss 1.930387\n",
      "iteration 0 / 1500: loss 5.440184\n",
      "iteration 100 / 1500: loss 2.106836\n",
      "iteration 200 / 1500: loss 2.069947\n",
      "iteration 300 / 1500: loss 2.040655\n",
      "iteration 400 / 1500: loss 2.076018\n",
      "iteration 500 / 1500: loss 2.074837\n",
      "iteration 600 / 1500: loss 2.042714\n",
      "iteration 700 / 1500: loss 1.987817\n",
      "iteration 800 / 1500: loss 2.051075\n",
      "iteration 900 / 1500: loss 2.001200\n",
      "iteration 1000 / 1500: loss 1.975346\n",
      "iteration 1100 / 1500: loss 2.024403\n",
      "iteration 1200 / 1500: loss 2.038124\n",
      "iteration 1300 / 1500: loss 2.017182\n",
      "iteration 1400 / 1500: loss 2.066373\n",
      "iteration 0 / 1500: loss 6.668833\n",
      "iteration 100 / 1500: loss 2.205817\n",
      "iteration 200 / 1500: loss 2.161172\n",
      "iteration 300 / 1500: loss 2.114365\n",
      "iteration 400 / 1500: loss 2.125815\n",
      "iteration 500 / 1500: loss 2.125995\n",
      "iteration 600 / 1500: loss 2.159579\n",
      "iteration 700 / 1500: loss 2.131254\n",
      "iteration 800 / 1500: loss 2.139481\n",
      "iteration 900 / 1500: loss 2.089982\n",
      "iteration 1000 / 1500: loss 2.118266\n",
      "iteration 1100 / 1500: loss 2.126580\n",
      "iteration 1200 / 1500: loss 2.120464\n",
      "iteration 1300 / 1500: loss 2.129891\n",
      "iteration 1400 / 1500: loss 2.111733\n",
      "iteration 0 / 1500: loss 4.595903\n",
      "iteration 100 / 1500: loss 2.358149\n",
      "iteration 200 / 1500: loss 1.915314\n",
      "iteration 300 / 1500: loss 1.890009\n",
      "iteration 400 / 1500: loss 1.826578\n",
      "iteration 500 / 1500: loss 1.771486\n",
      "iteration 600 / 1500: loss 1.877382\n",
      "iteration 700 / 1500: loss 1.805756\n",
      "iteration 800 / 1500: loss 1.753167\n",
      "iteration 900 / 1500: loss 1.811167\n",
      "iteration 1000 / 1500: loss 1.832052\n",
      "iteration 1100 / 1500: loss 1.797442\n",
      "iteration 1200 / 1500: loss 1.802869\n",
      "iteration 1300 / 1500: loss 1.718986\n",
      "iteration 1400 / 1500: loss 1.706502\n",
      "iteration 0 / 1500: loss 5.832213\n",
      "iteration 100 / 1500: loss 2.057345\n",
      "iteration 200 / 1500: loss 2.063040\n",
      "iteration 300 / 1500: loss 2.087094\n",
      "iteration 400 / 1500: loss 2.004449\n",
      "iteration 500 / 1500: loss 2.080413\n",
      "iteration 600 / 1500: loss 2.030146\n",
      "iteration 700 / 1500: loss 2.045841\n",
      "iteration 800 / 1500: loss 2.079685\n",
      "iteration 900 / 1500: loss 2.074259\n",
      "iteration 1000 / 1500: loss 2.117616\n",
      "iteration 1100 / 1500: loss 2.064582\n",
      "iteration 1200 / 1500: loss 2.091471\n",
      "iteration 1300 / 1500: loss 2.082322\n",
      "iteration 1400 / 1500: loss 2.037774\n",
      "iteration 0 / 1500: loss 5.083475\n",
      "iteration 100 / 1500: loss 2.765970\n",
      "iteration 200 / 1500: loss 2.278309\n",
      "iteration 300 / 1500: loss 2.109287\n",
      "iteration 400 / 1500: loss 1.996164\n",
      "iteration 500 / 1500: loss 1.868585\n",
      "iteration 600 / 1500: loss 1.983870\n",
      "iteration 700 / 1500: loss 1.836146\n",
      "iteration 800 / 1500: loss 1.898039\n",
      "iteration 900 / 1500: loss 1.833894\n",
      "iteration 1000 / 1500: loss 1.869886\n",
      "iteration 1100 / 1500: loss 1.867965\n",
      "iteration 1200 / 1500: loss 1.855611\n",
      "iteration 1300 / 1500: loss 1.875926\n",
      "iteration 1400 / 1500: loss 1.856849\n",
      "iteration 0 / 1500: loss 6.266933\n",
      "iteration 100 / 1500: loss 2.967892\n",
      "iteration 200 / 1500: loss 2.576447\n",
      "iteration 300 / 1500: loss 2.312244\n",
      "iteration 400 / 1500: loss 2.373963\n",
      "iteration 500 / 1500: loss 2.281555\n",
      "iteration 600 / 1500: loss 2.178187\n",
      "iteration 700 / 1500: loss 2.097799\n",
      "iteration 800 / 1500: loss 1.953588\n",
      "iteration 900 / 1500: loss 2.074909\n",
      "iteration 1000 / 1500: loss 1.927450\n",
      "iteration 1100 / 1500: loss 1.979965\n",
      "iteration 1200 / 1500: loss 1.928672\n",
      "iteration 1300 / 1500: loss 1.870844\n",
      "iteration 1400 / 1500: loss 1.942272\n",
      "iteration 0 / 1500: loss 7.185414\n",
      "iteration 100 / 1500: loss 2.260896\n",
      "iteration 200 / 1500: loss 2.269530\n",
      "iteration 300 / 1500: loss 2.247104\n",
      "iteration 400 / 1500: loss 2.252927\n",
      "iteration 500 / 1500: loss 2.267360\n",
      "iteration 600 / 1500: loss 2.261892\n",
      "iteration 700 / 1500: loss 2.259379\n",
      "iteration 800 / 1500: loss 2.253532\n",
      "iteration 900 / 1500: loss 2.256651\n",
      "iteration 1000 / 1500: loss 2.263355\n",
      "iteration 1100 / 1500: loss 2.261939\n",
      "iteration 1200 / 1500: loss 2.256668\n",
      "iteration 1300 / 1500: loss 2.258633\n",
      "iteration 1400 / 1500: loss 2.255384\n",
      "iteration 0 / 1500: loss 4.804712\n",
      "iteration 100 / 1500: loss 3.815988\n",
      "iteration 200 / 1500: loss 3.301727\n",
      "iteration 300 / 1500: loss 3.002105\n",
      "iteration 400 / 1500: loss 2.983173\n",
      "iteration 500 / 1500: loss 3.031015\n",
      "iteration 600 / 1500: loss 2.981412\n",
      "iteration 700 / 1500: loss 2.514587\n",
      "iteration 800 / 1500: loss 2.357778\n",
      "iteration 900 / 1500: loss 2.755311\n",
      "iteration 1000 / 1500: loss 2.837479\n",
      "iteration 1100 / 1500: loss 2.409751\n",
      "iteration 1200 / 1500: loss 2.576170\n",
      "iteration 1300 / 1500: loss 2.603152\n",
      "iteration 1400 / 1500: loss 2.399392\n",
      "iteration 0 / 1500: loss 6.593322\n",
      "iteration 100 / 1500: loss 2.046165\n",
      "iteration 200 / 1500: loss 2.114501\n",
      "iteration 300 / 1500: loss 2.055850\n",
      "iteration 400 / 1500: loss 2.085566\n",
      "iteration 500 / 1500: loss 2.068835\n",
      "iteration 600 / 1500: loss 2.083444\n",
      "iteration 700 / 1500: loss 2.088956\n",
      "iteration 800 / 1500: loss 2.142141\n",
      "iteration 900 / 1500: loss 2.081087\n",
      "iteration 1000 / 1500: loss 2.057910\n",
      "iteration 1100 / 1500: loss 2.093898\n",
      "iteration 1200 / 1500: loss 2.083665\n",
      "iteration 1300 / 1500: loss 2.094978\n",
      "iteration 1400 / 1500: loss 2.115770\n",
      "iteration 0 / 1500: loss 5.628889\n",
      "iteration 100 / 1500: loss 2.121316\n",
      "iteration 200 / 1500: loss 1.828642\n",
      "iteration 300 / 1500: loss 1.837970\n",
      "iteration 400 / 1500: loss 1.864472\n",
      "iteration 500 / 1500: loss 1.893172\n",
      "iteration 600 / 1500: loss 1.927062\n",
      "iteration 700 / 1500: loss 1.796609\n",
      "iteration 800 / 1500: loss 1.933669\n",
      "iteration 900 / 1500: loss 1.791645\n",
      "iteration 1000 / 1500: loss 1.886112\n",
      "iteration 1100 / 1500: loss 1.846815\n",
      "iteration 1200 / 1500: loss 1.874792\n",
      "iteration 1300 / 1500: loss 1.814828\n",
      "iteration 1400 / 1500: loss 1.810543\n",
      "iteration 0 / 1500: loss 6.053213\n",
      "iteration 100 / 1500: loss 3.218686\n",
      "iteration 200 / 1500: loss 2.849022\n",
      "iteration 300 / 1500: loss 2.492106\n",
      "iteration 400 / 1500: loss 2.429968\n",
      "iteration 500 / 1500: loss 2.607806\n",
      "iteration 600 / 1500: loss 2.305977\n",
      "iteration 700 / 1500: loss 2.298216\n",
      "iteration 800 / 1500: loss 2.328587\n",
      "iteration 900 / 1500: loss 2.194493\n",
      "iteration 1000 / 1500: loss 2.187262\n",
      "iteration 1100 / 1500: loss 1.910271\n",
      "iteration 1200 / 1500: loss 2.008699\n",
      "iteration 1300 / 1500: loss 1.980075\n",
      "iteration 1400 / 1500: loss 2.004684\n",
      "iteration 0 / 1500: loss 6.205491\n",
      "iteration 100 / 1500: loss 2.111008\n",
      "iteration 200 / 1500: loss 2.135052\n",
      "iteration 300 / 1500: loss 2.141877\n",
      "iteration 400 / 1500: loss 2.159912\n",
      "iteration 500 / 1500: loss 2.083495\n",
      "iteration 600 / 1500: loss 2.141916\n",
      "iteration 700 / 1500: loss 2.085495\n",
      "iteration 800 / 1500: loss 2.078731\n",
      "iteration 900 / 1500: loss 2.122085\n",
      "iteration 1000 / 1500: loss 2.114318\n",
      "iteration 1100 / 1500: loss 2.085103\n",
      "iteration 1200 / 1500: loss 2.116402\n",
      "iteration 1300 / 1500: loss 2.127388\n",
      "iteration 1400 / 1500: loss 2.113936\n",
      "iteration 0 / 1500: loss 5.708665\n",
      "iteration 100 / 1500: loss 2.259293\n",
      "iteration 200 / 1500: loss 2.255568\n",
      "iteration 300 / 1500: loss 2.252265\n",
      "iteration 400 / 1500: loss 2.272368\n",
      "iteration 500 / 1500: loss 2.260222\n",
      "iteration 600 / 1500: loss 2.254891\n",
      "iteration 700 / 1500: loss 2.255808\n",
      "iteration 800 / 1500: loss 2.260080\n",
      "iteration 900 / 1500: loss 2.262734\n",
      "iteration 1000 / 1500: loss 2.269282\n",
      "iteration 1100 / 1500: loss 2.238345\n",
      "iteration 1200 / 1500: loss 2.260798\n",
      "iteration 1300 / 1500: loss 2.248616\n",
      "iteration 1400 / 1500: loss 2.258862\n",
      "iteration 0 / 1500: loss 5.458154\n",
      "iteration 100 / 1500: loss 2.520481\n",
      "iteration 200 / 1500: loss 1.993733\n",
      "iteration 300 / 1500: loss 1.987333\n",
      "iteration 400 / 1500: loss 2.011153\n",
      "iteration 500 / 1500: loss 2.040225\n",
      "iteration 600 / 1500: loss 1.974225\n",
      "iteration 700 / 1500: loss 2.050736\n",
      "iteration 800 / 1500: loss 1.957542\n",
      "iteration 900 / 1500: loss 2.025749\n",
      "iteration 1000 / 1500: loss 1.972073\n",
      "iteration 1100 / 1500: loss 1.924685\n",
      "iteration 1200 / 1500: loss 2.011525\n",
      "iteration 1300 / 1500: loss 1.932310\n",
      "iteration 1400 / 1500: loss 1.981824\n",
      "iteration 0 / 1500: loss 5.457421\n",
      "iteration 100 / 1500: loss 2.909739\n",
      "iteration 200 / 1500: loss 2.627059\n",
      "iteration 300 / 1500: loss 2.320168\n",
      "iteration 400 / 1500: loss 2.326005\n",
      "iteration 500 / 1500: loss 2.098928\n",
      "iteration 600 / 1500: loss 2.331436\n",
      "iteration 700 / 1500: loss 2.097970\n",
      "iteration 800 / 1500: loss 2.052346\n",
      "iteration 900 / 1500: loss 2.173482\n",
      "iteration 1000 / 1500: loss 1.976238\n",
      "iteration 1100 / 1500: loss 2.178922\n",
      "iteration 1200 / 1500: loss 1.832545\n",
      "iteration 1300 / 1500: loss 1.941219\n",
      "iteration 1400 / 1500: loss 1.883616\n",
      "iteration 0 / 1500: loss 4.904120\n",
      "iteration 100 / 1500: loss 3.343652\n",
      "iteration 200 / 1500: loss 2.830337\n",
      "iteration 300 / 1500: loss 3.092095\n",
      "iteration 400 / 1500: loss 2.441089\n",
      "iteration 500 / 1500: loss 2.432571\n",
      "iteration 600 / 1500: loss 2.301535\n",
      "iteration 700 / 1500: loss 2.348216\n",
      "iteration 800 / 1500: loss 2.375022\n",
      "iteration 900 / 1500: loss 2.133005\n",
      "iteration 1000 / 1500: loss 2.224902\n",
      "iteration 1100 / 1500: loss 2.228850\n",
      "iteration 1200 / 1500: loss 2.054492\n",
      "iteration 1300 / 1500: loss 2.050635\n",
      "iteration 1400 / 1500: loss 2.250700\n",
      "iteration 0 / 1500: loss 5.205453\n",
      "iteration 100 / 1500: loss 2.114450\n",
      "iteration 200 / 1500: loss 2.177487\n",
      "iteration 300 / 1500: loss 2.148453\n",
      "iteration 400 / 1500: loss 2.191773\n",
      "iteration 500 / 1500: loss 2.150572\n",
      "iteration 600 / 1500: loss 2.130158\n",
      "iteration 700 / 1500: loss 2.092039\n",
      "iteration 800 / 1500: loss 2.174448\n",
      "iteration 900 / 1500: loss 2.153241\n",
      "iteration 1000 / 1500: loss 2.183113\n",
      "iteration 1100 / 1500: loss 2.154982\n",
      "iteration 1200 / 1500: loss 2.168953\n",
      "iteration 1300 / 1500: loss 2.146808\n",
      "iteration 1400 / 1500: loss 2.174765\n",
      "iteration 0 / 1500: loss 6.291545\n",
      "iteration 100 / 1500: loss 1.906868\n",
      "iteration 200 / 1500: loss 1.811035\n",
      "iteration 300 / 1500: loss 1.886241\n",
      "iteration 400 / 1500: loss 1.902975\n",
      "iteration 500 / 1500: loss 1.931854\n",
      "iteration 600 / 1500: loss 1.869497\n",
      "iteration 700 / 1500: loss 1.889195\n",
      "iteration 800 / 1500: loss 1.853908\n",
      "iteration 900 / 1500: loss 1.827238\n",
      "iteration 1000 / 1500: loss 1.830961\n",
      "iteration 1100 / 1500: loss 1.870203\n",
      "iteration 1200 / 1500: loss 1.819328\n",
      "iteration 1300 / 1500: loss 1.847185\n",
      "iteration 1400 / 1500: loss 1.886812\n",
      "iteration 0 / 1500: loss 6.441069\n",
      "iteration 100 / 1500: loss 2.904231\n",
      "iteration 200 / 1500: loss 2.688910\n",
      "iteration 300 / 1500: loss 2.389246\n",
      "iteration 400 / 1500: loss 2.629923\n",
      "iteration 500 / 1500: loss 2.573685\n",
      "iteration 600 / 1500: loss 2.371381\n",
      "iteration 700 / 1500: loss 2.204113\n",
      "iteration 800 / 1500: loss 2.040937\n",
      "iteration 900 / 1500: loss 2.116112\n",
      "iteration 1000 / 1500: loss 1.939425\n",
      "iteration 1100 / 1500: loss 2.230771\n",
      "iteration 1200 / 1500: loss 1.908470\n",
      "iteration 1300 / 1500: loss 2.077120\n",
      "iteration 1400 / 1500: loss 1.859995\n",
      "iteration 0 / 1500: loss 6.023180\n",
      "iteration 100 / 1500: loss 2.474365\n",
      "iteration 200 / 1500: loss 2.227011\n",
      "iteration 300 / 1500: loss 2.077204\n",
      "iteration 400 / 1500: loss 2.103718\n",
      "iteration 500 / 1500: loss 1.929279\n",
      "iteration 600 / 1500: loss 1.953423\n",
      "iteration 700 / 1500: loss 1.797333\n",
      "iteration 800 / 1500: loss 1.721102\n",
      "iteration 900 / 1500: loss 1.853393\n",
      "iteration 1000 / 1500: loss 1.785266\n",
      "iteration 1100 / 1500: loss 1.817041\n",
      "iteration 1200 / 1500: loss 1.808724\n",
      "iteration 1300 / 1500: loss 1.692396\n",
      "iteration 1400 / 1500: loss 1.750356\n",
      "iteration 0 / 1500: loss 5.474043\n",
      "iteration 100 / 1500: loss 3.457213\n",
      "iteration 200 / 1500: loss 2.885287\n",
      "iteration 300 / 1500: loss 2.932613\n",
      "iteration 400 / 1500: loss 2.620735\n",
      "iteration 500 / 1500: loss 2.425666\n",
      "iteration 600 / 1500: loss 2.335205\n",
      "iteration 700 / 1500: loss 2.302414\n",
      "iteration 800 / 1500: loss 2.217374\n",
      "iteration 900 / 1500: loss 2.191004\n",
      "iteration 1000 / 1500: loss 2.074968\n",
      "iteration 1100 / 1500: loss 2.015904\n",
      "iteration 1200 / 1500: loss 2.132897\n",
      "iteration 1300 / 1500: loss 2.072163\n",
      "iteration 1400 / 1500: loss 1.996454\n",
      "iteration 0 / 1500: loss 5.424196\n",
      "iteration 100 / 1500: loss 2.331306\n",
      "iteration 200 / 1500: loss 2.017008\n",
      "iteration 300 / 1500: loss 1.828774\n",
      "iteration 400 / 1500: loss 1.761478\n",
      "iteration 500 / 1500: loss 1.885118\n",
      "iteration 600 / 1500: loss 1.850940\n",
      "iteration 700 / 1500: loss 1.806005\n",
      "iteration 800 / 1500: loss 1.691459\n",
      "iteration 900 / 1500: loss 1.758967\n",
      "iteration 1000 / 1500: loss 1.793037\n",
      "iteration 1100 / 1500: loss 1.726977\n",
      "iteration 1200 / 1500: loss 1.639548\n",
      "iteration 1300 / 1500: loss 1.754332\n",
      "iteration 1400 / 1500: loss 1.836138\n",
      "iteration 0 / 1500: loss 4.962177\n",
      "iteration 100 / 1500: loss 2.107713\n",
      "iteration 200 / 1500: loss 2.068952\n",
      "iteration 300 / 1500: loss 2.044994\n",
      "iteration 400 / 1500: loss 2.032388\n",
      "iteration 500 / 1500: loss 2.068188\n",
      "iteration 600 / 1500: loss 2.050437\n",
      "iteration 700 / 1500: loss 2.016171\n",
      "iteration 800 / 1500: loss 2.030572\n",
      "iteration 900 / 1500: loss 2.043169\n",
      "iteration 1000 / 1500: loss 2.042505\n",
      "iteration 1100 / 1500: loss 2.043266\n",
      "iteration 1200 / 1500: loss 2.032572\n",
      "iteration 1300 / 1500: loss 2.030607\n",
      "iteration 1400 / 1500: loss 2.081017\n",
      "iteration 0 / 1500: loss 5.859191\n",
      "iteration 100 / 1500: loss 2.148728\n",
      "iteration 200 / 1500: loss 2.140231\n",
      "iteration 300 / 1500: loss 2.145144\n",
      "iteration 400 / 1500: loss 2.127675\n",
      "iteration 500 / 1500: loss 2.141449\n",
      "iteration 600 / 1500: loss 2.141675\n",
      "iteration 700 / 1500: loss 2.161832\n",
      "iteration 800 / 1500: loss 2.127911\n",
      "iteration 900 / 1500: loss 2.118564\n",
      "iteration 1000 / 1500: loss 2.189175\n",
      "iteration 1100 / 1500: loss 2.143061\n",
      "iteration 1200 / 1500: loss 2.157488\n",
      "iteration 1300 / 1500: loss 2.187903\n",
      "iteration 1400 / 1500: loss 2.165706\n",
      "iteration 0 / 1500: loss 5.925748\n",
      "iteration 100 / 1500: loss 2.014434\n",
      "iteration 200 / 1500: loss 1.986143\n",
      "iteration 300 / 1500: loss 1.989063\n",
      "iteration 400 / 1500: loss 1.994295\n",
      "iteration 500 / 1500: loss 2.034300\n",
      "iteration 600 / 1500: loss 2.009675\n",
      "iteration 700 / 1500: loss 1.967106\n",
      "iteration 800 / 1500: loss 2.028029\n",
      "iteration 900 / 1500: loss 1.967033\n",
      "iteration 1000 / 1500: loss 2.022054\n",
      "iteration 1100 / 1500: loss 2.023356\n",
      "iteration 1200 / 1500: loss 2.035615\n",
      "iteration 1300 / 1500: loss 2.012062\n",
      "iteration 1400 / 1500: loss 2.071748\n",
      "iteration 0 / 1500: loss 5.776396\n",
      "iteration 100 / 1500: loss 3.201151\n",
      "iteration 200 / 1500: loss 3.010212\n",
      "iteration 300 / 1500: loss 2.715552\n",
      "iteration 400 / 1500: loss 2.390263\n",
      "iteration 500 / 1500: loss 2.582027\n",
      "iteration 600 / 1500: loss 2.319385\n",
      "iteration 700 / 1500: loss 2.145378\n",
      "iteration 800 / 1500: loss 2.471900\n",
      "iteration 900 / 1500: loss 2.314653\n",
      "iteration 1000 / 1500: loss 2.197011\n",
      "iteration 1100 / 1500: loss 2.100868\n",
      "iteration 1200 / 1500: loss 2.078905\n",
      "iteration 1300 / 1500: loss 2.049855\n",
      "iteration 1400 / 1500: loss 2.031701\n",
      "iteration 0 / 1500: loss 5.118573\n",
      "iteration 100 / 1500: loss 2.012815\n",
      "iteration 200 / 1500: loss 1.985765\n",
      "iteration 300 / 1500: loss 2.035205\n",
      "iteration 400 / 1500: loss 2.022621\n",
      "iteration 500 / 1500: loss 1.970595\n",
      "iteration 600 / 1500: loss 2.033936\n",
      "iteration 700 / 1500: loss 1.934700\n",
      "iteration 800 / 1500: loss 1.994465\n",
      "iteration 900 / 1500: loss 1.959751\n",
      "iteration 1000 / 1500: loss 2.019916\n",
      "iteration 1100 / 1500: loss 2.034668\n",
      "iteration 1200 / 1500: loss 2.016074\n",
      "iteration 1300 / 1500: loss 2.064246\n",
      "iteration 1400 / 1500: loss 1.954743\n",
      "iteration 0 / 1500: loss 5.069640\n",
      "iteration 100 / 1500: loss 2.251314\n",
      "iteration 200 / 1500: loss 2.260949\n",
      "iteration 300 / 1500: loss 2.256923\n",
      "iteration 400 / 1500: loss 2.266678\n",
      "iteration 500 / 1500: loss 2.257655\n",
      "iteration 600 / 1500: loss 2.256738\n",
      "iteration 700 / 1500: loss 2.252133\n",
      "iteration 800 / 1500: loss 2.271207\n",
      "iteration 900 / 1500: loss 2.262158\n",
      "iteration 1000 / 1500: loss 2.261336\n",
      "iteration 1100 / 1500: loss 2.263844\n",
      "iteration 1200 / 1500: loss 2.265886\n",
      "iteration 1300 / 1500: loss 2.258889\n",
      "iteration 1400 / 1500: loss 2.261433\n",
      "iteration 0 / 1500: loss 6.933175\n",
      "iteration 100 / 1500: loss 2.199165\n",
      "iteration 200 / 1500: loss 1.935146\n",
      "iteration 300 / 1500: loss 1.958778\n",
      "iteration 400 / 1500: loss 1.965126\n",
      "iteration 500 / 1500: loss 1.954214\n",
      "iteration 600 / 1500: loss 1.893336\n",
      "iteration 700 / 1500: loss 1.885645\n",
      "iteration 800 / 1500: loss 1.952588\n",
      "iteration 900 / 1500: loss 1.998078\n",
      "iteration 1000 / 1500: loss 1.983860\n",
      "iteration 1100 / 1500: loss 1.930180\n",
      "iteration 1200 / 1500: loss 1.924191\n",
      "iteration 1300 / 1500: loss 1.913229\n",
      "iteration 1400 / 1500: loss 1.956513\n",
      "iteration 0 / 1500: loss 5.905868\n",
      "iteration 100 / 1500: loss 2.247634\n",
      "iteration 200 / 1500: loss 2.042622\n",
      "iteration 300 / 1500: loss 2.026471\n",
      "iteration 400 / 1500: loss 1.998162\n",
      "iteration 500 / 1500: loss 1.964817\n",
      "iteration 600 / 1500: loss 2.050820\n",
      "iteration 700 / 1500: loss 2.008172\n",
      "iteration 800 / 1500: loss 2.042082\n",
      "iteration 900 / 1500: loss 1.966869\n",
      "iteration 1000 / 1500: loss 1.976351\n",
      "iteration 1100 / 1500: loss 2.025849\n",
      "iteration 1200 / 1500: loss 2.002259\n",
      "iteration 1300 / 1500: loss 1.996306\n",
      "iteration 1400 / 1500: loss 2.020646\n",
      "iteration 0 / 1500: loss 5.344285\n",
      "iteration 100 / 1500: loss 2.993947\n",
      "iteration 200 / 1500: loss 2.989889\n",
      "iteration 300 / 1500: loss 2.768714\n",
      "iteration 400 / 1500: loss 2.370222\n",
      "iteration 500 / 1500: loss 2.508454\n",
      "iteration 600 / 1500: loss 2.196336\n",
      "iteration 700 / 1500: loss 2.319360\n",
      "iteration 800 / 1500: loss 2.361217\n",
      "iteration 900 / 1500: loss 2.269410\n",
      "iteration 1000 / 1500: loss 2.174527\n",
      "iteration 1100 / 1500: loss 2.132394\n",
      "iteration 1200 / 1500: loss 2.096657\n",
      "iteration 1300 / 1500: loss 1.991338\n",
      "iteration 1400 / 1500: loss 2.209338\n",
      "iteration 0 / 1500: loss 4.992059\n",
      "iteration 100 / 1500: loss 2.139724\n",
      "iteration 200 / 1500: loss 1.874704\n",
      "iteration 300 / 1500: loss 1.872980\n",
      "iteration 400 / 1500: loss 1.825805\n",
      "iteration 500 / 1500: loss 1.854574\n",
      "iteration 600 / 1500: loss 1.862431\n",
      "iteration 700 / 1500: loss 1.860125\n",
      "iteration 800 / 1500: loss 1.838849\n",
      "iteration 900 / 1500: loss 1.846599\n",
      "iteration 1000 / 1500: loss 1.748350\n",
      "iteration 1100 / 1500: loss 1.823778\n",
      "iteration 1200 / 1500: loss 1.886304\n",
      "iteration 1300 / 1500: loss 1.780503\n",
      "iteration 1400 / 1500: loss 1.839395\n",
      "iteration 0 / 1500: loss 4.847050\n",
      "iteration 100 / 1500: loss 2.110066\n",
      "iteration 200 / 1500: loss 2.150840\n",
      "iteration 300 / 1500: loss 2.164048\n",
      "iteration 400 / 1500: loss 2.103622\n",
      "iteration 500 / 1500: loss 2.159836\n",
      "iteration 600 / 1500: loss 2.150794\n",
      "iteration 700 / 1500: loss 2.153753\n",
      "iteration 800 / 1500: loss 2.118496\n",
      "iteration 900 / 1500: loss 2.122814\n",
      "iteration 1000 / 1500: loss 2.116263\n",
      "iteration 1100 / 1500: loss 2.108162\n",
      "iteration 1200 / 1500: loss 2.144894\n",
      "iteration 1300 / 1500: loss 2.136723\n",
      "iteration 1400 / 1500: loss 2.133876\n",
      "iteration 0 / 1500: loss 5.250286\n",
      "iteration 100 / 1500: loss 2.005734\n",
      "iteration 200 / 1500: loss 1.911906\n",
      "iteration 300 / 1500: loss 1.970821\n",
      "iteration 400 / 1500: loss 1.949039\n",
      "iteration 500 / 1500: loss 1.807728\n",
      "iteration 600 / 1500: loss 1.806888\n",
      "iteration 700 / 1500: loss 1.862115\n",
      "iteration 800 / 1500: loss 1.915949\n",
      "iteration 900 / 1500: loss 1.912185\n",
      "iteration 1000 / 1500: loss 1.938975\n",
      "iteration 1100 / 1500: loss 1.952270\n",
      "iteration 1200 / 1500: loss 1.889548\n",
      "iteration 1300 / 1500: loss 1.913487\n",
      "iteration 1400 / 1500: loss 1.901602\n",
      "iteration 0 / 1500: loss 4.946571\n",
      "iteration 100 / 1500: loss 1.950019\n",
      "iteration 200 / 1500: loss 1.904352\n",
      "iteration 300 / 1500: loss 1.961506\n",
      "iteration 400 / 1500: loss 1.935636\n",
      "iteration 500 / 1500: loss 1.837913\n",
      "iteration 600 / 1500: loss 1.933631\n",
      "iteration 700 / 1500: loss 1.888898\n",
      "iteration 800 / 1500: loss 1.994075\n",
      "iteration 900 / 1500: loss 1.957152\n",
      "iteration 1000 / 1500: loss 1.951568\n",
      "iteration 1100 / 1500: loss 1.912855\n",
      "iteration 1200 / 1500: loss 1.926160\n",
      "iteration 1300 / 1500: loss 1.834896\n",
      "iteration 1400 / 1500: loss 1.962746\n",
      "iteration 0 / 1500: loss 5.689866\n",
      "iteration 100 / 1500: loss 2.437023\n",
      "iteration 200 / 1500: loss 1.956324\n",
      "iteration 300 / 1500: loss 1.954287\n",
      "iteration 400 / 1500: loss 1.747116\n",
      "iteration 500 / 1500: loss 1.796079\n",
      "iteration 600 / 1500: loss 1.923252\n",
      "iteration 700 / 1500: loss 1.771687\n",
      "iteration 800 / 1500: loss 1.757872\n",
      "iteration 900 / 1500: loss 1.936756\n",
      "iteration 1000 / 1500: loss 1.862330\n",
      "iteration 1100 / 1500: loss 1.858967\n",
      "iteration 1200 / 1500: loss 1.835198\n",
      "iteration 1300 / 1500: loss 1.800662\n",
      "iteration 1400 / 1500: loss 1.743411\n",
      "iteration 0 / 1500: loss 6.109060\n",
      "iteration 100 / 1500: loss 3.508503\n",
      "iteration 200 / 1500: loss 2.829018\n",
      "iteration 300 / 1500: loss 2.704380\n",
      "iteration 400 / 1500: loss 2.546932\n",
      "iteration 500 / 1500: loss 2.457990\n",
      "iteration 600 / 1500: loss 2.095347\n",
      "iteration 700 / 1500: loss 2.224397\n",
      "iteration 800 / 1500: loss 2.165921\n",
      "iteration 900 / 1500: loss 2.083831\n",
      "iteration 1000 / 1500: loss 1.952780\n",
      "iteration 1100 / 1500: loss 2.046058\n",
      "iteration 1200 / 1500: loss 1.931726\n",
      "iteration 1300 / 1500: loss 1.922922\n",
      "iteration 1400 / 1500: loss 1.930568\n",
      "iteration 0 / 1500: loss 5.718514\n",
      "iteration 100 / 1500: loss 3.198890\n",
      "iteration 200 / 1500: loss 3.234446\n",
      "iteration 300 / 1500: loss 2.553612\n",
      "iteration 400 / 1500: loss 2.335987\n",
      "iteration 500 / 1500: loss 2.376783\n",
      "iteration 600 / 1500: loss 2.206178\n",
      "iteration 700 / 1500: loss 2.110275\n",
      "iteration 800 / 1500: loss 2.042318\n",
      "iteration 900 / 1500: loss 1.887488\n",
      "iteration 1000 / 1500: loss 1.971291\n",
      "iteration 1100 / 1500: loss 1.982416\n",
      "iteration 1200 / 1500: loss 2.028006\n",
      "iteration 1300 / 1500: loss 2.013611\n",
      "iteration 1400 / 1500: loss 2.031888\n",
      "iteration 0 / 1500: loss 4.611366\n",
      "iteration 100 / 1500: loss 1.999591\n",
      "iteration 200 / 1500: loss 1.920976\n",
      "iteration 300 / 1500: loss 1.925258\n",
      "iteration 400 / 1500: loss 1.873920\n",
      "iteration 500 / 1500: loss 1.883728\n",
      "iteration 600 / 1500: loss 1.974520\n",
      "iteration 700 / 1500: loss 1.892902\n",
      "iteration 800 / 1500: loss 1.950665\n",
      "iteration 900 / 1500: loss 1.873815\n",
      "iteration 1000 / 1500: loss 1.896566\n",
      "iteration 1100 / 1500: loss 1.958356\n",
      "iteration 1200 / 1500: loss 2.020367\n",
      "iteration 1300 / 1500: loss 1.935706\n",
      "iteration 1400 / 1500: loss 2.005549\n",
      "iteration 0 / 1500: loss 5.643524\n",
      "iteration 100 / 1500: loss 2.005615\n",
      "iteration 200 / 1500: loss 2.057601\n",
      "iteration 300 / 1500: loss 1.976345\n",
      "iteration 400 / 1500: loss 2.017173\n",
      "iteration 500 / 1500: loss 1.971698\n",
      "iteration 600 / 1500: loss 2.008766\n",
      "iteration 700 / 1500: loss 2.017841\n",
      "iteration 800 / 1500: loss 2.057893\n",
      "iteration 900 / 1500: loss 2.103973\n",
      "iteration 1000 / 1500: loss 2.050019\n",
      "iteration 1100 / 1500: loss 1.970274\n",
      "iteration 1200 / 1500: loss 2.032856\n",
      "iteration 1300 / 1500: loss 2.017024\n",
      "iteration 1400 / 1500: loss 2.004173\n",
      "iteration 0 / 1500: loss 5.494346\n",
      "iteration 100 / 1500: loss 2.619727\n",
      "iteration 200 / 1500: loss 2.339332\n",
      "iteration 300 / 1500: loss 2.124749\n",
      "iteration 400 / 1500: loss 1.811603\n",
      "iteration 500 / 1500: loss 1.920994\n",
      "iteration 600 / 1500: loss 1.804016\n",
      "iteration 700 / 1500: loss 1.884006\n",
      "iteration 800 / 1500: loss 1.788020\n",
      "iteration 900 / 1500: loss 1.750700\n",
      "iteration 1000 / 1500: loss 1.744950\n",
      "iteration 1100 / 1500: loss 1.796499\n",
      "iteration 1200 / 1500: loss 1.802370\n",
      "iteration 1300 / 1500: loss 1.745547\n",
      "iteration 1400 / 1500: loss 1.811171\n",
      "iteration 0 / 1500: loss 6.074815\n",
      "iteration 100 / 1500: loss 2.087120\n",
      "iteration 200 / 1500: loss 1.787122\n",
      "iteration 300 / 1500: loss 1.864766\n",
      "iteration 400 / 1500: loss 1.740405\n",
      "iteration 500 / 1500: loss 1.755594\n",
      "iteration 600 / 1500: loss 1.956797\n",
      "iteration 700 / 1500: loss 1.717351\n",
      "iteration 800 / 1500: loss 1.884625\n",
      "iteration 900 / 1500: loss 1.794338\n",
      "iteration 1000 / 1500: loss 1.818103\n",
      "iteration 1100 / 1500: loss 1.780215\n",
      "iteration 1200 / 1500: loss 1.776052\n",
      "iteration 1300 / 1500: loss 1.746135\n",
      "iteration 1400 / 1500: loss 1.700890\n",
      "iteration 0 / 1500: loss 6.004736\n",
      "iteration 100 / 1500: loss 2.197970\n",
      "iteration 200 / 1500: loss 1.954288\n",
      "iteration 300 / 1500: loss 1.965564\n",
      "iteration 400 / 1500: loss 1.821474\n",
      "iteration 500 / 1500: loss 1.837350\n",
      "iteration 600 / 1500: loss 1.795199\n",
      "iteration 700 / 1500: loss 1.741587\n",
      "iteration 800 / 1500: loss 1.761550\n",
      "iteration 900 / 1500: loss 1.921853\n",
      "iteration 1000 / 1500: loss 1.815342\n",
      "iteration 1100 / 1500: loss 1.877280\n",
      "iteration 1200 / 1500: loss 1.818435\n",
      "iteration 1300 / 1500: loss 1.848860\n",
      "iteration 1400 / 1500: loss 1.849592\n",
      "iteration 0 / 1500: loss 5.599753\n",
      "iteration 100 / 1500: loss 2.013753\n",
      "iteration 200 / 1500: loss 1.988072\n",
      "iteration 300 / 1500: loss 2.026579\n",
      "iteration 400 / 1500: loss 2.039001\n",
      "iteration 500 / 1500: loss 2.027538\n",
      "iteration 600 / 1500: loss 2.024763\n",
      "iteration 700 / 1500: loss 2.070126\n",
      "iteration 800 / 1500: loss 2.012335\n",
      "iteration 900 / 1500: loss 2.064838\n",
      "iteration 1000 / 1500: loss 2.077330\n",
      "iteration 1100 / 1500: loss 2.025272\n",
      "iteration 1200 / 1500: loss 2.045340\n",
      "iteration 1300 / 1500: loss 2.060904\n",
      "iteration 1400 / 1500: loss 2.058614\n",
      "iteration 0 / 1500: loss 5.960615\n",
      "iteration 100 / 1500: loss 2.092298\n",
      "iteration 200 / 1500: loss 1.878519\n",
      "iteration 300 / 1500: loss 1.850081\n",
      "iteration 400 / 1500: loss 1.723171\n",
      "iteration 500 / 1500: loss 1.785387\n",
      "iteration 600 / 1500: loss 1.860889\n",
      "iteration 700 / 1500: loss 1.733909\n",
      "iteration 800 / 1500: loss 1.935122\n",
      "iteration 900 / 1500: loss 1.780436\n",
      "iteration 1000 / 1500: loss 1.916594\n",
      "iteration 1100 / 1500: loss 1.809791\n",
      "iteration 1200 / 1500: loss 1.833141\n",
      "iteration 1300 / 1500: loss 1.814793\n",
      "iteration 1400 / 1500: loss 1.742855\n",
      "iteration 0 / 1500: loss 5.098034\n",
      "iteration 100 / 1500: loss 1.934731\n",
      "iteration 200 / 1500: loss 1.877117\n",
      "iteration 300 / 1500: loss 1.869627\n",
      "iteration 400 / 1500: loss 1.904723\n",
      "iteration 500 / 1500: loss 1.881233\n",
      "iteration 600 / 1500: loss 1.876832\n",
      "iteration 700 / 1500: loss 1.934579\n",
      "iteration 800 / 1500: loss 1.956873\n",
      "iteration 900 / 1500: loss 1.895637\n",
      "iteration 1000 / 1500: loss 1.862532\n",
      "iteration 1100 / 1500: loss 1.943811\n",
      "iteration 1200 / 1500: loss 1.901064\n",
      "iteration 1300 / 1500: loss 1.840030\n",
      "iteration 1400 / 1500: loss 1.852249\n",
      "iteration 0 / 1500: loss 6.839150\n",
      "iteration 100 / 1500: loss 2.056772\n",
      "iteration 200 / 1500: loss 2.077611\n",
      "iteration 300 / 1500: loss 2.032773\n",
      "iteration 400 / 1500: loss 2.006804\n",
      "iteration 500 / 1500: loss 2.103993\n",
      "iteration 600 / 1500: loss 2.029755\n",
      "iteration 700 / 1500: loss 2.062169\n",
      "iteration 800 / 1500: loss 2.011646\n",
      "iteration 900 / 1500: loss 2.042676\n",
      "iteration 1000 / 1500: loss 2.060731\n",
      "iteration 1100 / 1500: loss 2.063440\n",
      "iteration 1200 / 1500: loss 2.119789\n",
      "iteration 1300 / 1500: loss 2.014907\n",
      "iteration 1400 / 1500: loss 2.007469\n",
      "iteration 0 / 1500: loss 6.062418\n",
      "iteration 100 / 1500: loss 2.280136\n",
      "iteration 200 / 1500: loss 2.040362\n",
      "iteration 300 / 1500: loss 1.948195\n",
      "iteration 400 / 1500: loss 1.769736\n",
      "iteration 500 / 1500: loss 1.634712\n",
      "iteration 600 / 1500: loss 1.806744\n",
      "iteration 700 / 1500: loss 1.778858\n",
      "iteration 800 / 1500: loss 1.687687\n",
      "iteration 900 / 1500: loss 1.802061\n",
      "iteration 1000 / 1500: loss 1.739644\n",
      "iteration 1100 / 1500: loss 1.937020\n",
      "iteration 1200 / 1500: loss 1.725999\n",
      "iteration 1300 / 1500: loss 1.794731\n",
      "iteration 1400 / 1500: loss 1.730386\n",
      "iteration 0 / 1500: loss 5.407658\n",
      "iteration 100 / 1500: loss 2.227993\n",
      "iteration 200 / 1500: loss 2.058844\n",
      "iteration 300 / 1500: loss 1.985018\n",
      "iteration 400 / 1500: loss 2.007277\n",
      "iteration 500 / 1500: loss 2.006242\n",
      "iteration 600 / 1500: loss 1.996244\n",
      "iteration 700 / 1500: loss 2.013929\n",
      "iteration 800 / 1500: loss 2.032126\n",
      "iteration 900 / 1500: loss 1.985937\n",
      "iteration 1000 / 1500: loss 2.025695\n",
      "iteration 1100 / 1500: loss 1.999427\n",
      "iteration 1200 / 1500: loss 1.997931\n",
      "iteration 1300 / 1500: loss 2.008810\n",
      "iteration 1400 / 1500: loss 1.994687\n",
      "iteration 0 / 1500: loss 5.738204\n",
      "iteration 100 / 1500: loss 1.969125\n",
      "iteration 200 / 1500: loss 1.996423\n",
      "iteration 300 / 1500: loss 1.943423\n",
      "iteration 400 / 1500: loss 2.031304\n",
      "iteration 500 / 1500: loss 2.006641\n",
      "iteration 600 / 1500: loss 2.037271\n",
      "iteration 700 / 1500: loss 1.958000\n",
      "iteration 800 / 1500: loss 2.008912\n",
      "iteration 900 / 1500: loss 1.977990\n",
      "iteration 1000 / 1500: loss 2.059864\n",
      "iteration 1100 / 1500: loss 2.012146\n",
      "iteration 1200 / 1500: loss 2.008514\n",
      "iteration 1300 / 1500: loss 2.067280\n",
      "iteration 1400 / 1500: loss 2.016529\n",
      "iteration 0 / 1500: loss 5.650838\n",
      "iteration 100 / 1500: loss 2.087821\n",
      "iteration 200 / 1500: loss 1.884634\n",
      "iteration 300 / 1500: loss 1.856948\n",
      "iteration 400 / 1500: loss 1.787717\n",
      "iteration 500 / 1500: loss 1.781248\n",
      "iteration 600 / 1500: loss 1.862279\n",
      "iteration 700 / 1500: loss 1.758073\n",
      "iteration 800 / 1500: loss 1.823174\n",
      "iteration 900 / 1500: loss 1.887120\n",
      "iteration 1000 / 1500: loss 1.793891\n",
      "iteration 1100 / 1500: loss 1.842806\n",
      "iteration 1200 / 1500: loss 1.785841\n",
      "iteration 1300 / 1500: loss 1.813576\n",
      "iteration 1400 / 1500: loss 1.891186\n",
      "iteration 0 / 1500: loss 5.565270\n",
      "iteration 100 / 1500: loss 2.603432\n",
      "iteration 200 / 1500: loss 2.107212\n",
      "iteration 300 / 1500: loss 2.013792\n",
      "iteration 400 / 1500: loss 1.840490\n",
      "iteration 500 / 1500: loss 2.062358\n",
      "iteration 600 / 1500: loss 1.928372\n",
      "iteration 700 / 1500: loss 1.842850\n",
      "iteration 800 / 1500: loss 1.963182\n",
      "iteration 900 / 1500: loss 1.920152\n",
      "iteration 1000 / 1500: loss 1.897349\n",
      "iteration 1100 / 1500: loss 1.927251\n",
      "iteration 1200 / 1500: loss 1.814025\n",
      "iteration 1300 / 1500: loss 1.834831\n",
      "iteration 1400 / 1500: loss 1.875121\n",
      "iteration 0 / 1500: loss 6.056210\n",
      "iteration 100 / 1500: loss 2.660057\n",
      "iteration 200 / 1500: loss 2.092559\n",
      "iteration 300 / 1500: loss 2.042450\n",
      "iteration 400 / 1500: loss 1.878508\n",
      "iteration 500 / 1500: loss 1.813506\n",
      "iteration 600 / 1500: loss 1.778934\n",
      "iteration 700 / 1500: loss 1.889697\n",
      "iteration 800 / 1500: loss 1.834748\n",
      "iteration 900 / 1500: loss 1.840738\n",
      "iteration 1000 / 1500: loss 1.792645\n",
      "iteration 1100 / 1500: loss 1.818541\n",
      "iteration 1200 / 1500: loss 1.699211\n",
      "iteration 1300 / 1500: loss 1.778090\n",
      "iteration 1400 / 1500: loss 1.778101\n",
      "iteration 0 / 1500: loss 4.470778\n",
      "iteration 100 / 1500: loss 2.146108\n",
      "iteration 200 / 1500: loss 2.148014\n",
      "iteration 300 / 1500: loss 2.154406\n",
      "iteration 400 / 1500: loss 2.165369\n",
      "iteration 500 / 1500: loss 2.158108\n",
      "iteration 600 / 1500: loss 2.151881\n",
      "iteration 700 / 1500: loss 2.145563\n",
      "iteration 800 / 1500: loss 2.138996\n",
      "iteration 900 / 1500: loss 2.154956\n",
      "iteration 1000 / 1500: loss 2.186129\n",
      "iteration 1100 / 1500: loss 2.119749\n",
      "iteration 1200 / 1500: loss 2.148077\n",
      "iteration 1300 / 1500: loss 2.104500\n",
      "iteration 1400 / 1500: loss 2.166737\n",
      "iteration 0 / 1500: loss 4.739324\n",
      "iteration 100 / 1500: loss 2.202958\n",
      "iteration 200 / 1500: loss 2.071727\n",
      "iteration 300 / 1500: loss 2.061901\n",
      "iteration 400 / 1500: loss 2.023145\n",
      "iteration 500 / 1500: loss 2.137562\n",
      "iteration 600 / 1500: loss 2.081694\n",
      "iteration 700 / 1500: loss 2.105106\n",
      "iteration 800 / 1500: loss 2.086641\n",
      "iteration 900 / 1500: loss 2.134648\n",
      "iteration 1000 / 1500: loss 2.070433\n",
      "iteration 1100 / 1500: loss 2.110599\n",
      "iteration 1200 / 1500: loss 2.056806\n",
      "iteration 1300 / 1500: loss 2.058780\n",
      "iteration 1400 / 1500: loss 2.086529\n",
      "iteration 0 / 1500: loss 5.734972\n",
      "iteration 100 / 1500: loss 3.630673\n",
      "iteration 200 / 1500: loss 3.207514\n",
      "iteration 300 / 1500: loss 3.232899\n",
      "iteration 400 / 1500: loss 2.816886\n",
      "iteration 500 / 1500: loss 2.735570\n",
      "iteration 600 / 1500: loss 2.519408\n",
      "iteration 700 / 1500: loss 2.505201\n",
      "iteration 800 / 1500: loss 2.617808\n",
      "iteration 900 / 1500: loss 2.445762\n",
      "iteration 1000 / 1500: loss 2.243453\n",
      "iteration 1100 / 1500: loss 2.272405\n",
      "iteration 1200 / 1500: loss 2.360212\n",
      "iteration 1300 / 1500: loss 2.251846\n",
      "iteration 1400 / 1500: loss 2.038037\n",
      "iteration 0 / 1500: loss 5.275578\n",
      "iteration 100 / 1500: loss 3.178088\n",
      "iteration 200 / 1500: loss 2.804271\n",
      "iteration 300 / 1500: loss 2.687140\n",
      "iteration 400 / 1500: loss 2.435885\n",
      "iteration 500 / 1500: loss 2.307837\n",
      "iteration 600 / 1500: loss 2.389146\n",
      "iteration 700 / 1500: loss 1.974045\n",
      "iteration 800 / 1500: loss 2.211733\n",
      "iteration 900 / 1500: loss 2.166655\n",
      "iteration 1000 / 1500: loss 2.298898\n",
      "iteration 1100 / 1500: loss 1.913357\n",
      "iteration 1200 / 1500: loss 1.905287\n",
      "iteration 1300 / 1500: loss 1.983909\n",
      "iteration 1400 / 1500: loss 2.069002\n",
      "iteration 0 / 1500: loss 6.023136\n",
      "iteration 100 / 1500: loss 2.149290\n",
      "iteration 200 / 1500: loss 2.009338\n",
      "iteration 300 / 1500: loss 1.976974\n",
      "iteration 400 / 1500: loss 1.952267\n",
      "iteration 500 / 1500: loss 1.980069\n",
      "iteration 600 / 1500: loss 1.942774\n",
      "iteration 700 / 1500: loss 2.004304\n",
      "iteration 800 / 1500: loss 1.969306\n",
      "iteration 900 / 1500: loss 1.933745\n",
      "iteration 1000 / 1500: loss 1.899589\n",
      "iteration 1100 / 1500: loss 2.003942\n",
      "iteration 1200 / 1500: loss 1.964787\n",
      "iteration 1300 / 1500: loss 1.898861\n",
      "iteration 1400 / 1500: loss 2.025808\n",
      "iteration 0 / 1500: loss 5.521189\n",
      "iteration 100 / 1500: loss 2.729643\n",
      "iteration 200 / 1500: loss 2.349179\n",
      "iteration 300 / 1500: loss 2.223556\n",
      "iteration 400 / 1500: loss 1.835477\n",
      "iteration 500 / 1500: loss 1.878968\n",
      "iteration 600 / 1500: loss 1.948033\n",
      "iteration 700 / 1500: loss 1.823455\n",
      "iteration 800 / 1500: loss 1.856327\n",
      "iteration 900 / 1500: loss 1.910392\n",
      "iteration 1000 / 1500: loss 1.812072\n",
      "iteration 1100 / 1500: loss 1.903741\n",
      "iteration 1200 / 1500: loss 1.749191\n",
      "iteration 1300 / 1500: loss 1.801020\n",
      "iteration 1400 / 1500: loss 1.926095\n",
      "iteration 0 / 1500: loss 6.299771\n",
      "iteration 100 / 1500: loss 2.180534\n",
      "iteration 200 / 1500: loss 2.207273\n",
      "iteration 300 / 1500: loss 2.263832\n",
      "iteration 400 / 1500: loss 2.189837\n",
      "iteration 500 / 1500: loss 2.134543\n",
      "iteration 600 / 1500: loss 2.166520\n",
      "iteration 700 / 1500: loss 2.193816\n",
      "iteration 800 / 1500: loss 2.230768\n",
      "iteration 900 / 1500: loss 2.217286\n",
      "iteration 1000 / 1500: loss 2.161337\n",
      "iteration 1100 / 1500: loss 2.250394\n",
      "iteration 1200 / 1500: loss 2.183736\n",
      "iteration 1300 / 1500: loss 2.231698\n",
      "iteration 1400 / 1500: loss 2.193342\n",
      "iteration 0 / 1500: loss 6.084449\n",
      "iteration 100 / 1500: loss 2.200819\n",
      "iteration 200 / 1500: loss 2.180479\n",
      "iteration 300 / 1500: loss 2.145922\n",
      "iteration 400 / 1500: loss 2.172966\n",
      "iteration 500 / 1500: loss 2.169242\n",
      "iteration 600 / 1500: loss 2.184353\n",
      "iteration 700 / 1500: loss 2.150646\n",
      "iteration 800 / 1500: loss 2.179896\n",
      "iteration 900 / 1500: loss 2.145503\n",
      "iteration 1000 / 1500: loss 2.168550\n",
      "iteration 1100 / 1500: loss 2.188997\n",
      "iteration 1200 / 1500: loss 2.181305\n",
      "iteration 1300 / 1500: loss 2.158297\n",
      "iteration 1400 / 1500: loss 2.159230\n",
      "iteration 0 / 1500: loss 4.810973\n",
      "iteration 100 / 1500: loss 2.105174\n",
      "iteration 200 / 1500: loss 2.060207\n",
      "iteration 300 / 1500: loss 2.080794\n",
      "iteration 400 / 1500: loss 2.096073\n",
      "iteration 500 / 1500: loss 2.075430\n",
      "iteration 600 / 1500: loss 2.082585\n",
      "iteration 700 / 1500: loss 2.116465\n",
      "iteration 800 / 1500: loss 2.039502\n",
      "iteration 900 / 1500: loss 2.074961\n",
      "iteration 1000 / 1500: loss 2.060769\n",
      "iteration 1100 / 1500: loss 2.111625\n",
      "iteration 1200 / 1500: loss 2.052460\n",
      "iteration 1300 / 1500: loss 2.051798\n",
      "iteration 1400 / 1500: loss 2.115759\n",
      "iteration 0 / 1500: loss 6.404979\n",
      "iteration 100 / 1500: loss 1.944928\n",
      "iteration 200 / 1500: loss 1.977848\n",
      "iteration 300 / 1500: loss 2.018393\n",
      "iteration 400 / 1500: loss 2.022154\n",
      "iteration 500 / 1500: loss 2.023124\n",
      "iteration 600 / 1500: loss 1.931967\n",
      "iteration 700 / 1500: loss 1.975825\n",
      "iteration 800 / 1500: loss 1.968114\n",
      "iteration 900 / 1500: loss 1.994401\n",
      "iteration 1000 / 1500: loss 2.000257\n",
      "iteration 1100 / 1500: loss 2.026814\n",
      "iteration 1200 / 1500: loss 1.986776\n",
      "iteration 1300 / 1500: loss 2.018449\n",
      "iteration 1400 / 1500: loss 2.042299\n",
      "iteration 0 / 1500: loss 4.990580\n",
      "iteration 100 / 1500: loss 2.820713\n",
      "iteration 200 / 1500: loss 2.299507\n",
      "iteration 300 / 1500: loss 2.203511\n",
      "iteration 400 / 1500: loss 2.352686\n",
      "iteration 500 / 1500: loss 2.045555\n",
      "iteration 600 / 1500: loss 2.136838\n",
      "iteration 700 / 1500: loss 1.954921\n",
      "iteration 800 / 1500: loss 2.152890\n",
      "iteration 900 / 1500: loss 1.975523\n",
      "iteration 1000 / 1500: loss 2.001955\n",
      "iteration 1100 / 1500: loss 1.861110\n",
      "iteration 1200 / 1500: loss 1.925033\n",
      "iteration 1300 / 1500: loss 1.877516\n",
      "iteration 1400 / 1500: loss 1.801208\n",
      "iteration 0 / 1500: loss 4.910362\n",
      "iteration 100 / 1500: loss 2.015419\n",
      "iteration 200 / 1500: loss 2.084347\n",
      "iteration 300 / 1500: loss 2.027689\n",
      "iteration 400 / 1500: loss 1.977881\n",
      "iteration 500 / 1500: loss 1.985613\n",
      "iteration 600 / 1500: loss 2.043419\n",
      "iteration 700 / 1500: loss 1.978080\n",
      "iteration 800 / 1500: loss 2.021177\n",
      "iteration 900 / 1500: loss 1.920334\n",
      "iteration 1000 / 1500: loss 1.946119\n",
      "iteration 1100 / 1500: loss 2.017773\n",
      "iteration 1200 / 1500: loss 2.007147\n",
      "iteration 1300 / 1500: loss 2.050460\n",
      "iteration 1400 / 1500: loss 2.002860\n",
      "iteration 0 / 1500: loss 5.511003\n",
      "iteration 100 / 1500: loss 1.769789\n",
      "iteration 200 / 1500: loss 1.905270\n",
      "iteration 300 / 1500: loss 1.933752\n",
      "iteration 400 / 1500: loss 1.871350\n",
      "iteration 500 / 1500: loss 1.857516\n",
      "iteration 600 / 1500: loss 1.936761\n",
      "iteration 700 / 1500: loss 1.837050\n",
      "iteration 800 / 1500: loss 1.708038\n",
      "iteration 900 / 1500: loss 1.811388\n",
      "iteration 1000 / 1500: loss 1.836211\n",
      "iteration 1100 / 1500: loss 1.968789\n",
      "iteration 1200 / 1500: loss 1.880106\n",
      "iteration 1300 / 1500: loss 1.984493\n",
      "iteration 1400 / 1500: loss 1.802928\n",
      "iteration 0 / 1500: loss 4.994499\n",
      "iteration 100 / 1500: loss 2.213853\n",
      "iteration 200 / 1500: loss 2.200924\n",
      "iteration 300 / 1500: loss 2.181850\n",
      "iteration 400 / 1500: loss 2.205849\n",
      "iteration 500 / 1500: loss 2.187992\n",
      "iteration 600 / 1500: loss 2.216977\n",
      "iteration 700 / 1500: loss 2.217202\n",
      "iteration 800 / 1500: loss 2.215896\n",
      "iteration 900 / 1500: loss 2.177043\n",
      "iteration 1000 / 1500: loss 2.191356\n",
      "iteration 1100 / 1500: loss 2.194026\n",
      "iteration 1200 / 1500: loss 2.210908\n",
      "iteration 1300 / 1500: loss 2.169744\n",
      "iteration 1400 / 1500: loss 2.206717\n",
      "iteration 0 / 1500: loss 5.574940\n",
      "iteration 100 / 1500: loss 1.912407\n",
      "iteration 200 / 1500: loss 1.828378\n",
      "iteration 300 / 1500: loss 1.870694\n",
      "iteration 400 / 1500: loss 1.853578\n",
      "iteration 500 / 1500: loss 1.865003\n",
      "iteration 600 / 1500: loss 1.808156\n",
      "iteration 700 / 1500: loss 1.758746\n",
      "iteration 800 / 1500: loss 1.851634\n",
      "iteration 900 / 1500: loss 1.872177\n",
      "iteration 1000 / 1500: loss 1.849260\n",
      "iteration 1100 / 1500: loss 1.868863\n",
      "iteration 1200 / 1500: loss 1.891451\n",
      "iteration 1300 / 1500: loss 1.768126\n",
      "iteration 1400 / 1500: loss 1.898912\n",
      "iteration 0 / 1500: loss 5.682895\n",
      "iteration 100 / 1500: loss 3.645658\n",
      "iteration 200 / 1500: loss 3.017398\n",
      "iteration 300 / 1500: loss 2.506578\n",
      "iteration 400 / 1500: loss 2.375655\n",
      "iteration 500 / 1500: loss 2.414434\n",
      "iteration 600 / 1500: loss 2.168123\n",
      "iteration 700 / 1500: loss 2.024254\n",
      "iteration 800 / 1500: loss 2.029105\n",
      "iteration 900 / 1500: loss 1.951684\n",
      "iteration 1000 / 1500: loss 1.968779\n",
      "iteration 1100 / 1500: loss 1.943520\n",
      "iteration 1200 / 1500: loss 1.802657\n",
      "iteration 1300 / 1500: loss 1.921920\n",
      "iteration 1400 / 1500: loss 1.832450\n",
      "iteration 0 / 1500: loss 5.415314\n",
      "iteration 100 / 1500: loss 2.189704\n",
      "iteration 200 / 1500: loss 2.214556\n",
      "iteration 300 / 1500: loss 2.209646\n",
      "iteration 400 / 1500: loss 2.213272\n",
      "iteration 500 / 1500: loss 2.177018\n",
      "iteration 600 / 1500: loss 2.222684\n",
      "iteration 700 / 1500: loss 2.193845\n",
      "iteration 800 / 1500: loss 2.180874\n",
      "iteration 900 / 1500: loss 2.203094\n",
      "iteration 1000 / 1500: loss 2.213309\n",
      "iteration 1100 / 1500: loss 2.206517\n",
      "iteration 1200 / 1500: loss 2.192683\n",
      "iteration 1300 / 1500: loss 2.207226\n",
      "iteration 1400 / 1500: loss 2.201269\n",
      "iteration 0 / 1500: loss 6.017675\n",
      "iteration 100 / 1500: loss 3.853886\n",
      "iteration 200 / 1500: loss 3.048295\n",
      "iteration 300 / 1500: loss 2.373985\n",
      "iteration 400 / 1500: loss 2.174538\n",
      "iteration 500 / 1500: loss 1.989467\n",
      "iteration 600 / 1500: loss 2.026505\n",
      "iteration 700 / 1500: loss 1.993307\n",
      "iteration 800 / 1500: loss 1.935958\n",
      "iteration 900 / 1500: loss 1.923394\n",
      "iteration 1000 / 1500: loss 1.873653\n",
      "iteration 1100 / 1500: loss 1.905254\n",
      "iteration 1200 / 1500: loss 1.858589\n",
      "iteration 1300 / 1500: loss 1.999020\n",
      "iteration 1400 / 1500: loss 1.910950\n",
      "iteration 0 / 1500: loss 5.810175\n",
      "iteration 100 / 1500: loss 3.391053\n",
      "iteration 200 / 1500: loss 2.804573\n",
      "iteration 300 / 1500: loss 2.706205\n",
      "iteration 400 / 1500: loss 2.382919\n",
      "iteration 500 / 1500: loss 2.264961\n",
      "iteration 600 / 1500: loss 2.147383\n",
      "iteration 700 / 1500: loss 2.089076\n",
      "iteration 800 / 1500: loss 2.050736\n",
      "iteration 900 / 1500: loss 2.000487\n",
      "iteration 1000 / 1500: loss 1.856158\n",
      "iteration 1100 / 1500: loss 1.867592\n",
      "iteration 1200 / 1500: loss 1.892232\n",
      "iteration 1300 / 1500: loss 1.950295\n",
      "iteration 1400 / 1500: loss 1.824270\n",
      "iteration 0 / 1500: loss 6.107672\n",
      "iteration 100 / 1500: loss 3.042803\n",
      "iteration 200 / 1500: loss 2.390274\n",
      "iteration 300 / 1500: loss 2.024283\n",
      "iteration 400 / 1500: loss 2.015269\n",
      "iteration 500 / 1500: loss 1.836024\n",
      "iteration 600 / 1500: loss 1.867766\n",
      "iteration 700 / 1500: loss 1.854429\n",
      "iteration 800 / 1500: loss 1.883045\n",
      "iteration 900 / 1500: loss 1.814191\n",
      "iteration 1000 / 1500: loss 1.764146\n",
      "iteration 1100 / 1500: loss 1.850370\n",
      "iteration 1200 / 1500: loss 1.860542\n",
      "iteration 1300 / 1500: loss 1.944830\n",
      "iteration 1400 / 1500: loss 1.834879\n",
      "iteration 0 / 1500: loss 6.062927\n",
      "iteration 100 / 1500: loss 2.194773\n",
      "iteration 200 / 1500: loss 2.198015\n",
      "iteration 300 / 1500: loss 2.179173\n",
      "iteration 400 / 1500: loss 2.224502\n",
      "iteration 500 / 1500: loss 2.196113\n",
      "iteration 600 / 1500: loss 2.167396\n",
      "iteration 700 / 1500: loss 2.192853\n",
      "iteration 800 / 1500: loss 2.236788\n",
      "iteration 900 / 1500: loss 2.201730\n",
      "iteration 1000 / 1500: loss 2.201937\n",
      "iteration 1100 / 1500: loss 2.179993\n",
      "iteration 1200 / 1500: loss 2.204766\n",
      "iteration 1300 / 1500: loss 2.210972\n",
      "iteration 1400 / 1500: loss 2.214876\n",
      "iteration 0 / 1500: loss 5.272990\n",
      "iteration 100 / 1500: loss 1.965519\n",
      "iteration 200 / 1500: loss 1.983839\n",
      "iteration 300 / 1500: loss 1.944135\n",
      "iteration 400 / 1500: loss 1.943077\n",
      "iteration 500 / 1500: loss 1.923168\n",
      "iteration 600 / 1500: loss 1.957737\n",
      "iteration 700 / 1500: loss 1.981440\n",
      "iteration 800 / 1500: loss 1.997927\n",
      "iteration 900 / 1500: loss 1.968268\n",
      "iteration 1000 / 1500: loss 1.943447\n",
      "iteration 1100 / 1500: loss 2.022238\n",
      "iteration 1200 / 1500: loss 1.946160\n",
      "iteration 1300 / 1500: loss 1.974956\n",
      "iteration 1400 / 1500: loss 1.940544\n",
      "iteration 0 / 1500: loss 5.160355\n",
      "iteration 100 / 1500: loss 2.088942\n",
      "iteration 200 / 1500: loss 1.945620\n",
      "iteration 300 / 1500: loss 2.015226\n",
      "iteration 400 / 1500: loss 2.014125\n",
      "iteration 500 / 1500: loss 2.009529\n",
      "iteration 600 / 1500: loss 2.042004\n",
      "iteration 700 / 1500: loss 2.030777\n",
      "iteration 800 / 1500: loss 2.016014\n",
      "iteration 900 / 1500: loss 2.033673\n",
      "iteration 1000 / 1500: loss 2.031435\n",
      "iteration 1100 / 1500: loss 2.069043\n",
      "iteration 1200 / 1500: loss 2.089956\n",
      "iteration 1300 / 1500: loss 2.026243\n",
      "iteration 1400 / 1500: loss 1.974213\n",
      "iteration 0 / 1500: loss 6.417860\n",
      "iteration 100 / 1500: loss 2.093636\n",
      "iteration 200 / 1500: loss 2.102421\n",
      "iteration 300 / 1500: loss 2.082908\n",
      "iteration 400 / 1500: loss 2.064974\n",
      "iteration 500 / 1500: loss 2.101103\n",
      "iteration 600 / 1500: loss 2.114841\n",
      "iteration 700 / 1500: loss 2.130820\n",
      "iteration 800 / 1500: loss 2.122192\n",
      "iteration 900 / 1500: loss 2.091478\n",
      "iteration 1000 / 1500: loss 2.065038\n",
      "iteration 1100 / 1500: loss 2.078253\n",
      "iteration 1200 / 1500: loss 2.084920\n",
      "iteration 1300 / 1500: loss 2.080177\n",
      "iteration 1400 / 1500: loss 2.094844\n",
      "iteration 0 / 1500: loss 5.201108\n",
      "iteration 100 / 1500: loss 2.810345\n",
      "iteration 200 / 1500: loss 2.115972\n",
      "iteration 300 / 1500: loss 2.268779\n",
      "iteration 400 / 1500: loss 2.179151\n",
      "iteration 500 / 1500: loss 2.165828\n",
      "iteration 600 / 1500: loss 1.999577\n",
      "iteration 700 / 1500: loss 1.997627\n",
      "iteration 800 / 1500: loss 1.935997\n",
      "iteration 900 / 1500: loss 1.810622\n",
      "iteration 1000 / 1500: loss 1.836747\n",
      "iteration 1100 / 1500: loss 1.768408\n",
      "iteration 1200 / 1500: loss 1.744564\n",
      "iteration 1300 / 1500: loss 1.931342\n",
      "iteration 1400 / 1500: loss 1.888944\n",
      "iteration 0 / 1500: loss 6.055114\n",
      "iteration 100 / 1500: loss 2.104265\n",
      "iteration 200 / 1500: loss 2.062562\n",
      "iteration 300 / 1500: loss 2.128015\n",
      "iteration 400 / 1500: loss 2.091430\n",
      "iteration 500 / 1500: loss 2.064297\n",
      "iteration 600 / 1500: loss 2.105848\n",
      "iteration 700 / 1500: loss 2.083474\n",
      "iteration 800 / 1500: loss 2.090560\n",
      "iteration 900 / 1500: loss 2.057323\n",
      "iteration 1000 / 1500: loss 2.135726\n",
      "iteration 1100 / 1500: loss 2.092064\n",
      "iteration 1200 / 1500: loss 2.105044\n",
      "iteration 1300 / 1500: loss 2.084895\n",
      "iteration 1400 / 1500: loss 2.080651\n",
      "iteration 0 / 1500: loss 4.577147\n",
      "iteration 100 / 1500: loss 2.256609\n",
      "iteration 200 / 1500: loss 2.241073\n",
      "iteration 300 / 1500: loss 2.252703\n",
      "iteration 400 / 1500: loss 2.245133\n",
      "iteration 500 / 1500: loss 2.250289\n",
      "iteration 600 / 1500: loss 2.236675\n",
      "iteration 700 / 1500: loss 2.254851\n",
      "iteration 800 / 1500: loss 2.230863\n",
      "iteration 900 / 1500: loss 2.241051\n",
      "iteration 1000 / 1500: loss 2.257728\n",
      "iteration 1100 / 1500: loss 2.241110\n",
      "iteration 1200 / 1500: loss 2.251740\n",
      "iteration 1300 / 1500: loss 2.247717\n",
      "iteration 1400 / 1500: loss 2.249847\n",
      "iteration 0 / 1500: loss 5.693024\n",
      "iteration 100 / 1500: loss 2.875966\n",
      "iteration 200 / 1500: loss 2.438489\n",
      "iteration 300 / 1500: loss 2.417567\n",
      "iteration 400 / 1500: loss 2.246619\n",
      "iteration 500 / 1500: loss 1.995964\n",
      "iteration 600 / 1500: loss 1.943868\n",
      "iteration 700 / 1500: loss 2.182598\n",
      "iteration 800 / 1500: loss 1.824752\n",
      "iteration 900 / 1500: loss 1.781642\n",
      "iteration 1000 / 1500: loss 1.940723\n",
      "iteration 1100 / 1500: loss 1.861785\n",
      "iteration 1200 / 1500: loss 1.718323\n",
      "iteration 1300 / 1500: loss 1.826419\n",
      "iteration 1400 / 1500: loss 1.818205\n",
      "iteration 0 / 1500: loss 6.369380\n",
      "iteration 100 / 1500: loss 2.191119\n",
      "iteration 200 / 1500: loss 2.161797\n",
      "iteration 300 / 1500: loss 2.171989\n",
      "iteration 400 / 1500: loss 2.139481\n",
      "iteration 500 / 1500: loss 2.217939\n",
      "iteration 600 / 1500: loss 2.157032\n",
      "iteration 700 / 1500: loss 2.136913\n",
      "iteration 800 / 1500: loss 2.181984\n",
      "iteration 900 / 1500: loss 2.158836\n",
      "iteration 1000 / 1500: loss 2.182289\n",
      "iteration 1100 / 1500: loss 2.160002\n",
      "iteration 1200 / 1500: loss 2.157804\n",
      "iteration 1300 / 1500: loss 2.149314\n",
      "iteration 1400 / 1500: loss 2.158358\n",
      "iteration 0 / 1500: loss 5.493381\n",
      "iteration 100 / 1500: loss 1.877096\n",
      "iteration 200 / 1500: loss 1.829502\n",
      "iteration 300 / 1500: loss 1.859835\n",
      "iteration 400 / 1500: loss 1.796838\n",
      "iteration 500 / 1500: loss 1.666391\n",
      "iteration 600 / 1500: loss 1.886178\n",
      "iteration 700 / 1500: loss 1.747772\n",
      "iteration 800 / 1500: loss 1.843384\n",
      "iteration 900 / 1500: loss 1.892274\n",
      "iteration 1000 / 1500: loss 1.764761\n",
      "iteration 1100 / 1500: loss 1.856081\n",
      "iteration 1200 / 1500: loss 1.929752\n",
      "iteration 1300 / 1500: loss 1.918204\n",
      "iteration 1400 / 1500: loss 1.913033\n",
      "iteration 0 / 1500: loss 5.601458\n",
      "iteration 100 / 1500: loss 2.883854\n",
      "iteration 200 / 1500: loss 2.564237\n",
      "iteration 300 / 1500: loss 2.283706\n",
      "iteration 400 / 1500: loss 2.288878\n",
      "iteration 500 / 1500: loss 2.186402\n",
      "iteration 600 / 1500: loss 2.182125\n",
      "iteration 700 / 1500: loss 2.112549\n",
      "iteration 800 / 1500: loss 2.276847\n",
      "iteration 900 / 1500: loss 2.012174\n",
      "iteration 1000 / 1500: loss 2.177571\n",
      "iteration 1100 / 1500: loss 1.863777\n",
      "iteration 1200 / 1500: loss 2.048751\n",
      "iteration 1300 / 1500: loss 2.056976\n",
      "iteration 1400 / 1500: loss 1.867509\n",
      "iteration 0 / 1500: loss 5.646349\n",
      "iteration 100 / 1500: loss 1.954393\n",
      "iteration 200 / 1500: loss 1.858738\n",
      "iteration 300 / 1500: loss 1.843812\n",
      "iteration 400 / 1500: loss 1.801393\n",
      "iteration 500 / 1500: loss 1.995437\n",
      "iteration 600 / 1500: loss 1.927998\n",
      "iteration 700 / 1500: loss 1.783738\n",
      "iteration 800 / 1500: loss 1.828340\n",
      "iteration 900 / 1500: loss 1.732073\n",
      "iteration 1000 / 1500: loss 1.931105\n",
      "iteration 1100 / 1500: loss 1.841184\n",
      "iteration 1200 / 1500: loss 1.871616\n",
      "iteration 1300 / 1500: loss 1.779950\n",
      "iteration 1400 / 1500: loss 1.789505\n",
      "iteration 0 / 1500: loss 4.792440\n",
      "iteration 100 / 1500: loss 3.516129\n",
      "iteration 200 / 1500: loss 3.428694\n",
      "iteration 300 / 1500: loss 2.883057\n",
      "iteration 400 / 1500: loss 2.725536\n",
      "iteration 500 / 1500: loss 2.574324\n",
      "iteration 600 / 1500: loss 2.717746\n",
      "iteration 700 / 1500: loss 2.426876\n",
      "iteration 800 / 1500: loss 2.559426\n",
      "iteration 900 / 1500: loss 2.396083\n",
      "iteration 1000 / 1500: loss 2.290871\n",
      "iteration 1100 / 1500: loss 2.256098\n",
      "iteration 1200 / 1500: loss 2.155068\n",
      "iteration 1300 / 1500: loss 2.213725\n",
      "iteration 1400 / 1500: loss 2.050817\n",
      "iteration 0 / 1500: loss 5.190623\n",
      "iteration 100 / 1500: loss 3.315544\n",
      "iteration 200 / 1500: loss 3.407536\n",
      "iteration 300 / 1500: loss 2.811325\n",
      "iteration 400 / 1500: loss 2.531870\n",
      "iteration 500 / 1500: loss 2.474164\n",
      "iteration 600 / 1500: loss 2.590390\n",
      "iteration 700 / 1500: loss 2.293889\n",
      "iteration 800 / 1500: loss 2.308699\n",
      "iteration 900 / 1500: loss 2.018416\n",
      "iteration 1000 / 1500: loss 2.190608\n",
      "iteration 1100 / 1500: loss 2.221118\n",
      "iteration 1200 / 1500: loss 2.109132\n",
      "iteration 1300 / 1500: loss 2.157496\n",
      "iteration 1400 / 1500: loss 2.067452\n",
      "lr 1.017737e-07 reg 4.313202e+02 train accuracy: 0.261184 val accuracy: 0.264000\n",
      "lr 1.028141e-07 reg 3.690659e+02 train accuracy: 0.255592 val accuracy: 0.261000\n",
      "lr 1.040448e-07 reg 1.000664e+05 train accuracy: 0.289143 val accuracy: 0.299000\n",
      "lr 1.047939e-07 reg 8.792707e+05 train accuracy: 0.232714 val accuracy: 0.244000\n",
      "lr 1.149104e-07 reg 7.280068e+03 train accuracy: 0.359469 val accuracy: 0.373000\n",
      "lr 1.255865e-07 reg 5.335141e+04 train accuracy: 0.293490 val accuracy: 0.313000\n",
      "lr 1.309016e-07 reg 1.333508e+03 train accuracy: 0.290061 val accuracy: 0.299000\n",
      "lr 1.311489e-07 reg 4.148728e+03 train accuracy: 0.351490 val accuracy: 0.358000\n",
      "lr 1.369793e-07 reg 1.012822e+03 train accuracy: 0.281449 val accuracy: 0.268000\n",
      "lr 1.477414e-07 reg 1.193665e+04 train accuracy: 0.353551 val accuracy: 0.362000\n",
      "lr 1.526729e-07 reg 5.769898e+05 train accuracy: 0.263327 val accuracy: 0.264000\n",
      "lr 1.564715e-07 reg 2.331335e+04 train accuracy: 0.331755 val accuracy: 0.346000\n",
      "lr 1.600353e-07 reg 2.825382e+03 train accuracy: 0.346510 val accuracy: 0.364000\n",
      "lr 1.784238e-07 reg 7.931875e+05 train accuracy: 0.250245 val accuracy: 0.262000\n",
      "lr 1.826990e-07 reg 1.455165e+03 train accuracy: 0.326306 val accuracy: 0.331000\n",
      "lr 1.963673e-07 reg 1.611087e+03 train accuracy: 0.335224 val accuracy: 0.337000\n",
      "lr 2.075246e-07 reg 7.966306e+05 train accuracy: 0.247551 val accuracy: 0.262000\n",
      "lr 2.117464e-07 reg 6.520594e+02 train accuracy: 0.306816 val accuracy: 0.302000\n",
      "lr 2.219780e-07 reg 2.618917e+04 train accuracy: 0.329939 val accuracy: 0.342000\n",
      "lr 2.394673e-07 reg 1.199429e+03 train accuracy: 0.338531 val accuracy: 0.344000\n",
      "lr 2.414152e-07 reg 3.658143e+04 train accuracy: 0.311857 val accuracy: 0.330000\n",
      "lr 2.445999e-07 reg 6.923401e+03 train accuracy: 0.367776 val accuracy: 0.383000\n",
      "lr 2.471619e-07 reg 6.528418e+04 train accuracy: 0.289245 val accuracy: 0.304000\n",
      "lr 2.481988e-07 reg 9.849516e+04 train accuracy: 0.280878 val accuracy: 0.296000\n",
      "lr 2.759153e-07 reg 4.324424e+02 train accuracy: 0.316429 val accuracy: 0.302000\n",
      "lr 2.783152e-07 reg 2.174608e+04 train accuracy: 0.330959 val accuracy: 0.359000\n",
      "lr 2.801583e-07 reg 2.464349e+05 train accuracy: 0.273061 val accuracy: 0.282000\n",
      "lr 2.832973e-07 reg 4.690988e+03 train accuracy: 0.377408 val accuracy: 0.385000\n",
      "lr 2.934550e-07 reg 5.281844e+02 train accuracy: 0.325612 val accuracy: 0.323000\n",
      "lr 2.987185e-07 reg 7.947514e+03 train accuracy: 0.363143 val accuracy: 0.378000\n",
      "lr 3.028513e-07 reg 3.665058e+02 train accuracy: 0.317245 val accuracy: 0.322000\n",
      "lr 3.087600e-07 reg 6.609792e+04 train accuracy: 0.307959 val accuracy: 0.321000\n",
      "lr 3.137667e-07 reg 2.135709e+02 train accuracy: 0.310551 val accuracy: 0.310000\n",
      "lr 3.196114e-07 reg 1.726163e+04 train accuracy: 0.328918 val accuracy: 0.340000\n",
      "lr 3.216384e-07 reg 3.556906e+04 train accuracy: 0.315408 val accuracy: 0.333000\n",
      "lr 3.535591e-07 reg 5.343544e+04 train accuracy: 0.309918 val accuracy: 0.316000\n",
      "lr 3.646565e-07 reg 1.619739e+02 train accuracy: 0.312837 val accuracy: 0.342000\n",
      "lr 3.743732e-07 reg 1.089226e+04 train accuracy: 0.356163 val accuracy: 0.380000\n",
      "lr 3.798812e-07 reg 2.603723e+05 train accuracy: 0.237306 val accuracy: 0.263000\n",
      "lr 3.902008e-07 reg 4.694471e+02 train accuracy: 0.350816 val accuracy: 0.365000\n",
      "lr 4.222703e-07 reg 9.436634e+04 train accuracy: 0.289510 val accuracy: 0.301000\n",
      "lr 4.227572e-07 reg 1.597127e+05 train accuracy: 0.257265 val accuracy: 0.277000\n",
      "lr 4.257668e-07 reg 1.875942e+02 train accuracy: 0.326163 val accuracy: 0.333000\n",
      "lr 4.412851e-07 reg 1.672693e+03 train accuracy: 0.389429 val accuracy: 0.393000\n",
      "lr 4.567472e-07 reg 2.137856e+02 train accuracy: 0.333265 val accuracy: 0.326000\n",
      "lr 4.885666e-07 reg 4.006519e+04 train accuracy: 0.318837 val accuracy: 0.331000\n",
      "lr 4.978100e-07 reg 1.694743e+02 train accuracy: 0.334918 val accuracy: 0.356000\n",
      "lr 5.054550e-07 reg 2.734206e+02 train accuracy: 0.343367 val accuracy: 0.331000\n",
      "lr 5.293073e-07 reg 3.926537e+04 train accuracy: 0.310714 val accuracy: 0.330000\n",
      "lr 5.475247e-07 reg 2.746310e+04 train accuracy: 0.324041 val accuracy: 0.333000\n",
      "lr 5.714317e-07 reg 1.709904e+04 train accuracy: 0.334653 val accuracy: 0.360000\n",
      "lr 5.735095e-07 reg 2.647900e+03 train accuracy: 0.382776 val accuracy: 0.400000\n",
      "lr 6.371984e-07 reg 1.151012e+02 train accuracy: 0.346571 val accuracy: 0.336000\n",
      "lr 6.408406e-07 reg 1.361481e+03 train accuracy: 0.398061 val accuracy: 0.406000\n",
      "lr 6.618021e-07 reg 6.488402e+04 train accuracy: 0.298653 val accuracy: 0.305000\n",
      "lr 7.130508e-07 reg 1.166722e+05 train accuracy: 0.270102 val accuracy: 0.287000\n",
      "lr 7.325663e-07 reg 3.928614e+02 train accuracy: 0.378633 val accuracy: 0.392000\n",
      "lr 7.495631e-07 reg 9.588106e+03 train accuracy: 0.356286 val accuracy: 0.363000\n",
      "lr 7.788288e-07 reg 2.669747e+03 train accuracy: 0.381816 val accuracy: 0.398000\n",
      "lr 8.061390e-07 reg 3.460338e+04 train accuracy: 0.315551 val accuracy: 0.324000\n",
      "lr 8.450474e-07 reg 6.841778e+04 train accuracy: 0.279306 val accuracy: 0.290000\n",
      "lr 8.626617e-07 reg 1.092793e+04 train accuracy: 0.347327 val accuracy: 0.354000\n",
      "lr 8.832693e-07 reg 1.382159e+02 train accuracy: 0.364898 val accuracy: 0.359000\n",
      "lr 9.279820e-07 reg 2.257338e+02 train accuracy: 0.379490 val accuracy: 0.379000\n",
      "lr 9.424528e-07 reg 1.337228e+02 train accuracy: 0.372000 val accuracy: 0.354000\n",
      "lr 9.801371e-07 reg 4.362239e+03 train accuracy: 0.373490 val accuracy: 0.372000\n",
      "lr 1.052976e-06 reg 2.425553e+05 train accuracy: 0.250286 val accuracy: 0.272000\n",
      "lr 1.149761e-06 reg 2.433631e+04 train accuracy: 0.321469 val accuracy: 0.322000\n",
      "lr 1.180203e-06 reg 3.057068e+04 train accuracy: 0.308061 val accuracy: 0.339000\n",
      "lr 1.277055e-06 reg 2.628583e+03 train accuracy: 0.375633 val accuracy: 0.371000\n",
      "lr 1.295837e-06 reg 3.000831e+03 train accuracy: 0.382061 val accuracy: 0.388000\n",
      "lr 1.308467e-06 reg 4.490373e+04 train accuracy: 0.301082 val accuracy: 0.312000\n",
      "lr 1.351349e-06 reg 3.648556e+03 train accuracy: 0.378980 val accuracy: 0.383000\n",
      "lr 1.448066e-06 reg 1.209721e+05 train accuracy: 0.262122 val accuracy: 0.266000\n",
      "lr 1.458959e-06 reg 1.365642e+03 train accuracy: 0.392327 val accuracy: 0.378000\n",
      "lr 1.505334e-06 reg 2.023414e+03 train accuracy: 0.384388 val accuracy: 0.385000\n",
      "lr 1.524835e-06 reg 1.278089e+05 train accuracy: 0.261878 val accuracy: 0.270000\n",
      "lr 1.581865e-06 reg 8.065072e+02 train accuracy: 0.396980 val accuracy: 0.384000\n",
      "lr 1.623531e-06 reg 6.556652e+02 train accuracy: 0.406490 val accuracy: 0.414000\n",
      "lr 1.661582e-06 reg 1.646639e+02 train accuracy: 0.408061 val accuracy: 0.391000\n",
      "lr 1.663535e-06 reg 1.681037e+03 train accuracy: 0.384592 val accuracy: 0.396000\n",
      "lr 1.700792e-06 reg 6.348980e+03 train accuracy: 0.353796 val accuracy: 0.352000\n",
      "lr 1.904227e-06 reg 3.870874e+04 train accuracy: 0.292633 val accuracy: 0.299000\n",
      "lr 1.936546e-06 reg 2.377708e+03 train accuracy: 0.370939 val accuracy: 0.376000\n",
      "lr 1.938209e-06 reg 5.436079e+03 train accuracy: 0.348837 val accuracy: 0.361000\n",
      "lr 1.944582e-06 reg 1.447607e+05 train accuracy: 0.202571 val accuracy: 0.206000\n",
      "lr 2.087443e-06 reg 3.160920e+03 train accuracy: 0.371245 val accuracy: 0.373000\n",
      "lr 2.099028e-06 reg 1.914121e+05 train accuracy: 0.249653 val accuracy: 0.258000\n",
      "lr 2.151493e-06 reg 3.771076e+03 train accuracy: 0.358286 val accuracy: 0.351000\n",
      "lr 2.221115e-06 reg 1.345527e+03 train accuracy: 0.385143 val accuracy: 0.401000\n",
      "lr 2.246282e-06 reg 7.447509e+03 train accuracy: 0.334245 val accuracy: 0.339000\n",
      "lr 2.247022e-06 reg 4.126766e+03 train accuracy: 0.358633 val accuracy: 0.367000\n",
      "lr 2.392694e-06 reg 1.139776e+04 train accuracy: 0.329714 val accuracy: 0.338000\n",
      "lr 2.392823e-06 reg 2.572617e+04 train accuracy: 0.291918 val accuracy: 0.317000\n",
      "lr 2.439917e-06 reg 1.899040e+04 train accuracy: 0.299102 val accuracy: 0.315000\n",
      "lr 2.536855e-06 reg 3.816248e+02 train accuracy: 0.393796 val accuracy: 0.394000\n",
      "lr 2.587189e-06 reg 2.160338e+04 train accuracy: 0.308449 val accuracy: 0.335000\n",
      "lr 2.841940e-06 reg 4.462478e+05 train accuracy: 0.100265 val accuracy: 0.087000\n",
      "lr 3.135161e-06 reg 1.300072e+03 train accuracy: 0.380776 val accuracy: 0.356000\n",
      "lr 3.136070e-06 reg 2.339103e+02 train accuracy: 0.400469 val accuracy: 0.393000\n",
      "best validation accuracy achieved during cross-validation: 0.414000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cs231n/classifiers/softmax.py:72: RuntimeWarning: overflow encountered in exp\n",
      "  expo = np.exp(scores)\n",
      "cs231n/classifiers/softmax.py:77: RuntimeWarning: invalid value encountered in divide\n",
      "  expo /= np.reshape(totals,(num_train,1))\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "max_count = 100\n",
    "for count in xrange(max_count):\n",
    "    lr = 10**np.random.uniform(-5.5,-7)\n",
    "    rg = 10**np.random.uniform(2,6)\n",
    "    sftm = Softmax()\n",
    "    loss_hist = sftm.train(X_train, y_train, learning_rate=lr, reg=rg,\n",
    "                      num_iters=1500, verbose=True)\n",
    "    y_train_pred = sftm.predict(X_train)\n",
    "    accu_train = np.mean(y_train == y_train_pred)\n",
    "    y_val_pred = sftm.predict(X_val)\n",
    "    accu_val = np.mean(y_val == y_val_pred)\n",
    "    if accu_val>best_val :\n",
    "        best_val = accu_val\n",
    "        best_softmax = sftm\n",
    "    results[(lr,rg)]= (accu_train,accu_val)\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.382000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBYqlaoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f201ae8e750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
